{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Tensorflow 2\n",
    "#### `Adapted from Rich Folsom article to include scikit-learn API and Confusion Matrix`\n",
    "https://towardsdatascience.com/tensorflow-2-0-data-transformation-for-text-classification-b86ee2ad8877\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import joblib\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "pd.set_option('max_colwidth', 500)\n",
    "print('tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstart = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix  #Required input to plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Inspired by Shay Palachy's function:  https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823\n",
    "def plot_confusion_matrix(confusion_matrix, class_names, errors_only=False, figsize = (15,6), fontsize=16):\n",
    "    \"\"\"\n",
    "    Plots confusion matrix as a color-encoded Seaborn heatmap.  Zeroes are\n",
    "    colored white.  Normalized values that are zero when rounded to three\n",
    "    decimals, Ex. 0.000, will be colored white.  Get more decicmals by\n",
    "    updating fmt, for example to '0.4f', and updating get_text() value.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object sklearn.metrics.confusion_matrix. \n",
    "    class_names: list\n",
    "        List of class names in the order they index the confusion matrix.\n",
    "    figsize: tuple\n",
    "        A pair tuple.  The first value is figure width.  The second\n",
    "        value is figure height. Defaults to (15,6).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 16.\n",
    "    \"\"\"        \n",
    "    #Instantiate Figure\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n",
    "    plt.subplots_adjust(wspace = 0.5)\n",
    "    \n",
    "    #Show errors only by filling diagonal with zeroes.\n",
    "    if errors_only:\n",
    "        np.fill_diagonal(confusion_matrix, 0)        \n",
    "        \n",
    "    # ax1 - Normalized Confusion Matrix    \n",
    "    #Normalize by dividing (M X M) matrix by (M X 1) matrix.  (M X 1) is row totals.\n",
    "    conf_matrix_norm = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:,np.newaxis]\n",
    "    conf_matrix_norm = np.nan_to_num(conf_matrix_norm)  #fix any nans caused by zero row total\n",
    "    df_cm_norm = pd.DataFrame(conf_matrix_norm, index=class_names, columns=class_names)\n",
    "    heatmap = sns.heatmap(df_cm_norm, ax=ax1, cmap='Blues', fmt='.3f', annot=True, annot_kws={\"size\": fontsize},\n",
    "              linewidths=2, linecolor='black', cbar=False)\n",
    "    \n",
    "    ax1.tick_params(axis='x', labelrotation=0, labelsize=fontsize, labelcolor='black')\n",
    "    ax1.tick_params(axis='y', labelrotation=0, labelsize=fontsize, labelcolor='black')\n",
    "    ax1.set_ylim(ax1.get_xlim()[0], ax1.get_xlim()[1])  #Fix messed up ylim\n",
    "    ax1.set_xlabel('PREDICTED CLASS', fontsize=fontsize, color='black')\n",
    "    ax1.set_ylabel('TRUE CLASS', fontsize=fontsize, color='black')\n",
    "    ax1.set_title('Confusion Matrix - Normalized', pad=15, fontsize=fontsize, color='black')\n",
    "    \n",
    "    # ax2 - Confusion Matrix - Class Counts\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names)    \n",
    "    heatmap = sns.heatmap(df_cm, ax=ax2, cmap='Blues', fmt='d', annot=True, annot_kws={\"size\": fontsize},\n",
    "              linewidths=2, linecolor='black', cbar=False)   \n",
    "    \n",
    "    ax2.tick_params(axis='x', labelrotation=0, labelsize=fontsize, labelcolor='black')\n",
    "    ax2.tick_params(axis='y', labelrotation=0, labelsize=fontsize, labelcolor='black')\n",
    "    ax2.set_ylim(ax1.get_xlim()[0], ax1.get_xlim()[1])  #Fix bug in matplotlib 3.1.1.  Or, use earlier matplotlib.\n",
    "    ax2.set_xlabel('PREDICTED CLASS', fontsize=fontsize, color='black')\n",
    "    ax2.set_ylabel('TRUE CLASS', fontsize=fontsize, color='black')\n",
    "    ax2.set_title('Confusion Matrix - Class Counts', pad=15, fontsize=fontsize, color='black')    \n",
    "  \n",
    "    for text in ax1.texts:\n",
    "        if text.get_text() == '0.000':\n",
    "            text.set_color(color='white')            \n",
    "    for text in ax2.texts:\n",
    "        if text.get_text() == '0':\n",
    "            text.set_color(color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Justin\\\\DATA_SCIENCE\\\\text_classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build train and test dataframes from individual review files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Build dataframes from train subfolders pos and neg.  Pos and neg contain reviews in individual text files.\n",
    "# def build_df(start_path):\n",
    "#     '''\n",
    "#     Append all files in the target folder.  Then return as dataframe.\n",
    "#     '''\n",
    "\n",
    "#     df = pd.DataFrame(columns=['review', 'sentim'])\n",
    "#     review = []\n",
    "#     sentim = []\n",
    "    \n",
    "#     for folder in ['neg','pos']:\n",
    "#         fpath=os.path.join(start_path, folder)\n",
    "#         files = [f for f in os.listdir(fpath)]\n",
    "        \n",
    "#         for f in files:\n",
    "#             with open(os.path.join(fpath, f), \"r\", encoding='utf8') as myfile:\n",
    "#                 # replace linefeed (\\n) and carriage return (\\r) with space\n",
    "#                 review.append(myfile.read().replace(\"\\n\", \" \").replace(\"\\r\", \" \"))\n",
    "#                 # convert positive reviews to 1 and negative reviews to zero\n",
    "#                 sentim.append(1 if folder == 'pos' else 0)\n",
    "\n",
    "#     df['review']=review\n",
    "#     df['sentim']=sentim\n",
    "#     #This line shuffles the data so you don't end with contiguous\n",
    "#     #blocks of positive and negative reviews\n",
    "#     df = df.sample(frac=1).reset_index(drop=True)      \n",
    "#     return df\n",
    "\n",
    "# #double backslash for Windows\n",
    "# train_df = build_df('aclImdb\\\\train')\n",
    "# test_df = build_df('aclImdb\\\\test')\n",
    "\n",
    "# #Save dataframes to disk.  Delete dataframes from memory.\n",
    "# joblib.dump(train_df, 'train_df.joblib', compress=1)\n",
    "# joblib.dump(test_df, 'test_df.joblib', compress=1)\n",
    "# del train_df\n",
    "# del test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataframes from disk.\n",
    "train_df = joblib.load('train_df.joblib')\n",
    "test_df = joblib.load('test_df.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Note: These comments are for people who have seen the movie.&lt;br /&gt;&lt;br /&gt;Vanilla Sky is a brilliant, complex, and thrilling movie that existentially explores exactly what the tag-line says: LoveHateDreamsLifeWorkPlayFriends. Maybe the movie plot can come into focus for confused movie-goers if one looks at it from a different angle.&lt;br /&gt;&lt;br /&gt;Considering the following:&lt;br /&gt;&lt;br /&gt;Now, I have not painstakingly gone through the film scene by scene, so I will have to further examine my assertion...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                review  \\\n",
       "0  Note: These comments are for people who have seen the movie.<br /><br />Vanilla Sky is a brilliant, complex, and thrilling movie that existentially explores exactly what the tag-line says: LoveHateDreamsLifeWorkPlayFriends. Maybe the movie plot can come into focus for confused movie-goers if one looks at it from a different angle.<br /><br />Considering the following:<br /><br />Now, I have not painstakingly gone through the film scene by scene, so I will have to further examine my assertion...   \n",
       "\n",
       "   sentim  \n",
       "0       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was an excellent show. It came on PBS back home in Chicago and I remember Cindy Herron (From EnVogue) played the teen aged daughter. The show dealt with subjects such as sex, peer pressure and puberty. IT was about a middle class black family who had a teen aged daughter and son who moved to a middle class neighborhood from Oakland or somewhere (I can't remember). I remember several episodes but the one I remember most was when their cousin got her period for the first time. I was proba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                review  \\\n",
       "0  This was an excellent show. It came on PBS back home in Chicago and I remember Cindy Herron (From EnVogue) played the teen aged daughter. The show dealt with subjects such as sex, peer pressure and puberty. IT was about a middle class black family who had a teen aged daughter and son who moved to a middle class neighborhood from Oakland or somewhere (I can't remember). I remember several episodes but the one I remember most was when their cousin got her period for the first time. I was proba...   \n",
       "\n",
       "   sentim  \n",
       "0       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert text to numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use keras tokenizer on reviews.  Need better tokenizer that uses the state-of-the-art cosine similarity?\n",
    "def text_to_integer_seqs(train=train_df, test=test_df, vocabSize=8000, SEQ_LEN=256):\n",
    "    '''\n",
    "    Tokenize text in train and test.  Convert text to integer sequences.  Pad or truncate each\n",
    "    sequence to SEQ_LEN.\n",
    "    \n",
    "    Returns numeric train and test.  Also returns tokenizer.\n",
    "    '''\n",
    "    #create tokenizer for our data\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocabSize, oov_token='<UNK>')\n",
    "    tokenizer.fit_on_texts(train['review'])\n",
    "    print(f\"## length of word index dictionary: {len(tokenizer.word_index)}\")\n",
    "    print(f\"## max number of most common words kept: {tokenizer.num_words}\")\n",
    "    \n",
    "    #convert review texts to various length integer sequences.\n",
    "    train_seqs=tokenizer.texts_to_sequences(train['review'])\n",
    "    test_seqs=tokenizer.texts_to_sequences(test['review'])  #Is this right for test???\n",
    "    print(f'## {len(train_seqs)} review texts are now integer sequences.')\n",
    "\n",
    "    #Adjust sequence lengths to 256 by padding or truncating.\n",
    "    train_seqs=tf.keras.preprocessing.sequence.pad_sequences(train_seqs, maxlen=SEQ_LEN, padding=\"post\")\n",
    "    test_seqs=tf.keras.preprocessing.sequence.pad_sequences(test_seqs, maxlen=SEQ_LEN, padding=\"post\")\n",
    "    print(f'## Length of first train seq: {len(train_seqs[0])}','\\n')\n",
    "    return train_seqs, test_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get model-friendly text features\n",
    "# train_seqs, test_seqs = text_to_integer_seqs(train=train_df, test=test_df, vocabSize=8000, SEQ_LEN=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocabSize=8000, embeddedDim=4):\n",
    "    \n",
    "    #Embedding: The vocabul_size is the input_dim. EMBEDDING_DIM is the embedding dimensions.\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocabSize, embeddedDim),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset current tensorflow session, learning phase, and graph.\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transparent Pipeline\n",
    "#### `Note:  We could also do these steps with sklearn.pipeline.Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## length of word index dictionary: 88581\n",
      "## max number of most common words kept: 8000\n",
      "## 25000 review texts are now integer sequences.\n",
      "## Length of first train seq: 256 \n",
      "\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=4, batch_size=16 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\Anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 4)           32000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 32,005\n",
      "Trainable params: 32,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13332 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13332/13332 [==============================] - 5s 370us/sample - loss: 0.6773 - accuracy: 0.6964 - val_loss: 0.6505 - val_accuracy: 0.7603\n",
      "Epoch 2/20\n",
      "13332/13332 [==============================] - 4s 277us/sample - loss: 0.6076 - accuracy: 0.7842 - val_loss: 0.5756 - val_accuracy: 0.7825\n",
      "Epoch 3/20\n",
      "13332/13332 [==============================] - 4s 267us/sample - loss: 0.5277 - accuracy: 0.8179 - val_loss: 0.5063 - val_accuracy: 0.8197\n",
      "Epoch 4/20\n",
      "13332/13332 [==============================] - 4s 270us/sample - loss: 0.4604 - accuracy: 0.8459 - val_loss: 0.4527 - val_accuracy: 0.8368\n",
      "Epoch 5/20\n",
      "13332/13332 [==============================] - 4s 269us/sample - loss: 0.4075 - accuracy: 0.8642 - val_loss: 0.4117 - val_accuracy: 0.8500\n",
      "Epoch 6/20\n",
      "13332/13332 [==============================] - 4s 275us/sample - loss: 0.3664 - accuracy: 0.8774 - val_loss: 0.3824 - val_accuracy: 0.8587\n",
      "Epoch 7/20\n",
      "13332/13332 [==============================] - 4s 266us/sample - loss: 0.3346 - accuracy: 0.8872 - val_loss: 0.3601 - val_accuracy: 0.8632\n",
      "Epoch 8/20\n",
      "13332/13332 [==============================] - 4s 266us/sample - loss: 0.3090 - accuracy: 0.8947 - val_loss: 0.3430 - val_accuracy: 0.8671\n",
      "Epoch 9/20\n",
      "13332/13332 [==============================] - 4s 266us/sample - loss: 0.2879 - accuracy: 0.9004 - val_loss: 0.3308 - val_accuracy: 0.8731\n",
      "Epoch 10/20\n",
      "13332/13332 [==============================] - 4s 272us/sample - loss: 0.2697 - accuracy: 0.9074 - val_loss: 0.3211 - val_accuracy: 0.8731\n",
      "8334/8334 [==============================] - 1s 131us/sample - loss: 0.3065 - accuracy: 0.8786\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=4, batch_size=16, total=  41.1s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=4, batch_size=16 .........\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 4)           32000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 32,005\n",
      "Trainable params: 32,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   41.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13333/13333 [==============================] - 4s 321us/sample - loss: 0.6813 - accuracy: 0.6639 - val_loss: 0.6580 - val_accuracy: 0.7555\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 4s 274us/sample - loss: 0.6167 - accuracy: 0.7844 - val_loss: 0.5816 - val_accuracy: 0.7921\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 4s 266us/sample - loss: 0.5352 - accuracy: 0.8175 - val_loss: 0.5116 - val_accuracy: 0.8212\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 4s 264us/sample - loss: 0.4655 - accuracy: 0.8441 - val_loss: 0.4559 - val_accuracy: 0.8383\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 4s 270us/sample - loss: 0.4102 - accuracy: 0.8624 - val_loss: 0.4139 - val_accuracy: 0.8503\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 4s 267us/sample - loss: 0.3683 - accuracy: 0.8740 - val_loss: 0.3834 - val_accuracy: 0.8542\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 4s 269us/sample - loss: 0.3356 - accuracy: 0.8847 - val_loss: 0.3605 - val_accuracy: 0.8623\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 4s 263us/sample - loss: 0.3098 - accuracy: 0.8922 - val_loss: 0.3440 - val_accuracy: 0.8653\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 4s 274us/sample - loss: 0.2883 - accuracy: 0.8978 - val_loss: 0.3319 - val_accuracy: 0.8692\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 4s 274us/sample - loss: 0.2705 - accuracy: 0.9042 - val_loss: 0.3223 - val_accuracy: 0.8722\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 4s 290us/sample - loss: 0.2551 - accuracy: 0.9090 - val_loss: 0.3132 - val_accuracy: 0.8746\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 4s 279us/sample - loss: 0.2412 - accuracy: 0.9140 - val_loss: 0.3088 - val_accuracy: 0.8734\n",
      "8333/8333 [==============================] - 1s 137us/sample - loss: 0.3022 - accuracy: 0.8806\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=4, batch_size=16, total=  45.4s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=4, batch_size=16 .........\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           32000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 32,005\n",
      "Trainable params: 32,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 4s 318us/sample - loss: 0.6752 - accuracy: 0.6980 - val_loss: 0.6483 - val_accuracy: 0.7603\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 4s 269us/sample - loss: 0.6059 - accuracy: 0.7894 - val_loss: 0.5692 - val_accuracy: 0.8050\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 4s 264us/sample - loss: 0.5246 - accuracy: 0.8273 - val_loss: 0.4981 - val_accuracy: 0.8332\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 4s 264us/sample - loss: 0.4550 - accuracy: 0.8514 - val_loss: 0.4418 - val_accuracy: 0.8554\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 4s 265us/sample - loss: 0.4007 - accuracy: 0.8684 - val_loss: 0.4016 - val_accuracy: 0.8617\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 4s 266us/sample - loss: 0.3598 - accuracy: 0.8804 - val_loss: 0.3711 - val_accuracy: 0.8674\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 4s 264us/sample - loss: 0.3280 - accuracy: 0.8883 - val_loss: 0.3470 - val_accuracy: 0.8734\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 3s 262us/sample - loss: 0.3027 - accuracy: 0.8952 - val_loss: 0.3292 - val_accuracy: 0.8767\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 4s 263us/sample - loss: 0.2818 - accuracy: 0.9017 - val_loss: 0.3175 - val_accuracy: 0.8791\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 4s 267us/sample - loss: 0.2641 - accuracy: 0.9066 - val_loss: 0.3062 - val_accuracy: 0.8818\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 4s 264us/sample - loss: 0.2487 - accuracy: 0.9130 - val_loss: 0.2964 - val_accuracy: 0.8842\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 4s 264us/sample - loss: 0.2353 - accuracy: 0.9187 - val_loss: 0.2919 - val_accuracy: 0.8860\n",
      "Epoch 13/20\n",
      "13333/13333 [==============================] - 4s 266us/sample - loss: 0.2230 - accuracy: 0.9240 - val_loss: 0.2847 - val_accuracy: 0.8893\n",
      "Epoch 14/20\n",
      "13333/13333 [==============================] - 4s 264us/sample - loss: 0.2119 - accuracy: 0.9275 - val_loss: 0.2811 - val_accuracy: 0.8902\n",
      "Epoch 15/20\n",
      "13333/13333 [==============================] - 4s 271us/sample - loss: 0.2017 - accuracy: 0.9311 - val_loss: 0.2776 - val_accuracy: 0.8941\n",
      "Epoch 16/20\n",
      "13333/13333 [==============================] - 4s 263us/sample - loss: 0.1923 - accuracy: 0.9350 - val_loss: 0.2752 - val_accuracy: 0.8938\n",
      "8333/8333 [==============================] - 1s 126us/sample - loss: 0.2996 - accuracy: 0.8758\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=4, batch_size=16, total=  58.5s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=8, batch_size=16 .........\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 8)           64000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 64,009\n",
      "Trainable params: 64,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13332 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13332/13332 [==============================] - 4s 327us/sample - loss: 0.6681 - accuracy: 0.6961 - val_loss: 0.6256 - val_accuracy: 0.7672\n",
      "Epoch 2/20\n",
      "13332/13332 [==============================] - 4s 283us/sample - loss: 0.5634 - accuracy: 0.7985 - val_loss: 0.5234 - val_accuracy: 0.8014\n",
      "Epoch 3/20\n",
      "13332/13332 [==============================] - 4s 277us/sample - loss: 0.4617 - accuracy: 0.8415 - val_loss: 0.4417 - val_accuracy: 0.8410\n",
      "Epoch 4/20\n",
      "13332/13332 [==============================] - 4s 275us/sample - loss: 0.3891 - accuracy: 0.8689 - val_loss: 0.3909 - val_accuracy: 0.8545\n",
      "Epoch 5/20\n",
      "13332/13332 [==============================] - 4s 276us/sample - loss: 0.3399 - accuracy: 0.8842 - val_loss: 0.3580 - val_accuracy: 0.8662\n",
      "Epoch 6/20\n",
      "13332/13332 [==============================] - 4s 290us/sample - loss: 0.3044 - accuracy: 0.8936 - val_loss: 0.3376 - val_accuracy: 0.8725\n",
      "Epoch 7/20\n",
      "13332/13332 [==============================] - 4s 283us/sample - loss: 0.2773 - accuracy: 0.9036 - val_loss: 0.3234 - val_accuracy: 0.8698\n",
      "8334/8334 [==============================] - 1s 134us/sample - loss: 0.3081 - accuracy: 0.8787\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=8, batch_size=16, total=  28.1s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=8, batch_size=16 .........\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 8)           64000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 64,009\n",
      "Trainable params: 64,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 4s 317us/sample - loss: 0.6661 - accuracy: 0.6912 - val_loss: 0.6236 - val_accuracy: 0.7633\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 4s 283us/sample - loss: 0.5615 - accuracy: 0.8052 - val_loss: 0.5171 - val_accuracy: 0.8098\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 4s 285us/sample - loss: 0.4586 - accuracy: 0.8459 - val_loss: 0.4386 - val_accuracy: 0.8455\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 4s 283us/sample - loss: 0.3858 - accuracy: 0.8700 - val_loss: 0.3880 - val_accuracy: 0.8554\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 4s 284us/sample - loss: 0.3361 - accuracy: 0.8854 - val_loss: 0.3559 - val_accuracy: 0.8629\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 4s 273us/sample - loss: 0.3013 - accuracy: 0.8955 - val_loss: 0.3357 - val_accuracy: 0.8674\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 4s 274us/sample - loss: 0.2743 - accuracy: 0.9021 - val_loss: 0.3211 - val_accuracy: 0.8707\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 4s 281us/sample - loss: 0.2529 - accuracy: 0.9098 - val_loss: 0.3114 - val_accuracy: 0.8737\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 4s 276us/sample - loss: 0.2343 - accuracy: 0.9170 - val_loss: 0.3058 - val_accuracy: 0.8749\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 4s 273us/sample - loss: 0.2185 - accuracy: 0.9222 - val_loss: 0.3012 - val_accuracy: 0.8764\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 4s 273us/sample - loss: 0.2047 - accuracy: 0.9287 - val_loss: 0.2961 - val_accuracy: 0.8782\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 4s 285us/sample - loss: 0.1919 - accuracy: 0.9330 - val_loss: 0.2985 - val_accuracy: 0.8776\n",
      "8333/8333 [==============================] - 1s 128us/sample - loss: 0.2896 - accuracy: 0.8841\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=8, batch_size=16, total=  46.4s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=8, batch_size=16 .........\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 8)           64000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_5 ( (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 64,009\n",
      "Trainable params: 64,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 4s 320us/sample - loss: 0.6639 - accuracy: 0.7045 - val_loss: 0.6193 - val_accuracy: 0.7675\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 4s 283us/sample - loss: 0.5567 - accuracy: 0.8097 - val_loss: 0.5093 - val_accuracy: 0.8218\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 4s 273us/sample - loss: 0.4534 - accuracy: 0.8516 - val_loss: 0.4294 - val_accuracy: 0.8548\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 4s 284us/sample - loss: 0.3806 - accuracy: 0.8732 - val_loss: 0.3774 - val_accuracy: 0.8695\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 4s 274us/sample - loss: 0.3316 - accuracy: 0.8868 - val_loss: 0.3457 - val_accuracy: 0.8716\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 4s 275us/sample - loss: 0.2970 - accuracy: 0.8978 - val_loss: 0.3244 - val_accuracy: 0.8749\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 4s 276us/sample - loss: 0.2704 - accuracy: 0.9053 - val_loss: 0.3060 - val_accuracy: 0.8827\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 4s 282us/sample - loss: 0.2490 - accuracy: 0.9127 - val_loss: 0.2941 - val_accuracy: 0.8857\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 4s 290us/sample - loss: 0.2308 - accuracy: 0.9188 - val_loss: 0.2897 - val_accuracy: 0.8860\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 4s 265us/sample - loss: 0.2151 - accuracy: 0.9247 - val_loss: 0.2825 - val_accuracy: 0.8896\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 4s 272us/sample - loss: 0.2010 - accuracy: 0.9308 - val_loss: 0.2760 - val_accuracy: 0.8923\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 4s 264us/sample - loss: 0.1887 - accuracy: 0.9355 - val_loss: 0.2770 - val_accuracy: 0.8905\n",
      "8333/8333 [==============================] - 1s 131us/sample - loss: 0.3010 - accuracy: 0.8735\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=8, batch_size=16, total=  46.0s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=16, batch_size=16 ........\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_6 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13332 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13332/13332 [==============================] - 5s 341us/sample - loss: 0.6502 - accuracy: 0.7156 - val_loss: 0.5829 - val_accuracy: 0.7861\n",
      "Epoch 2/20\n",
      "13332/13332 [==============================] - 4s 303us/sample - loss: 0.5015 - accuracy: 0.8243 - val_loss: 0.4592 - val_accuracy: 0.8305\n",
      "Epoch 3/20\n",
      "13332/13332 [==============================] - 4s 289us/sample - loss: 0.3899 - accuracy: 0.8648 - val_loss: 0.3811 - val_accuracy: 0.8620\n",
      "Epoch 4/20\n",
      "13332/13332 [==============================] - 4s 295us/sample - loss: 0.3245 - accuracy: 0.8886 - val_loss: 0.3434 - val_accuracy: 0.8671\n",
      "Epoch 5/20\n",
      "13332/13332 [==============================] - 4s 286us/sample - loss: 0.2833 - accuracy: 0.9012 - val_loss: 0.3218 - val_accuracy: 0.8719\n",
      "Epoch 6/20\n",
      "13332/13332 [==============================] - 4s 284us/sample - loss: 0.2527 - accuracy: 0.9121 - val_loss: 0.3096 - val_accuracy: 0.8764\n",
      "Epoch 7/20\n",
      "13332/13332 [==============================] - 4s 293us/sample - loss: 0.2286 - accuracy: 0.9215 - val_loss: 0.3038 - val_accuracy: 0.8797\n",
      "Epoch 8/20\n",
      "13332/13332 [==============================] - 4s 291us/sample - loss: 0.2085 - accuracy: 0.9279 - val_loss: 0.2982 - val_accuracy: 0.8776\n",
      "8334/8334 [==============================] - 1s 127us/sample - loss: 0.2798 - accuracy: 0.8864\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=16, batch_size=16, total=  33.0s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=16, batch_size=16 ........\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_7 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 5s 345us/sample - loss: 0.6495 - accuracy: 0.7191 - val_loss: 0.5829 - val_accuracy: 0.7723\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13333/13333 [==============================] - 4s 298us/sample - loss: 0.4999 - accuracy: 0.8272 - val_loss: 0.4513 - val_accuracy: 0.8335\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 4s 289us/sample - loss: 0.3870 - accuracy: 0.8669 - val_loss: 0.3786 - val_accuracy: 0.8572\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 4s 291us/sample - loss: 0.3220 - accuracy: 0.8861 - val_loss: 0.3415 - val_accuracy: 0.8668\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 4s 284us/sample - loss: 0.2805 - accuracy: 0.9011 - val_loss: 0.3205 - val_accuracy: 0.8713\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 4s 282us/sample - loss: 0.2511 - accuracy: 0.9112 - val_loss: 0.3089 - val_accuracy: 0.8758\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 4s 282us/sample - loss: 0.2274 - accuracy: 0.9183 - val_loss: 0.3007 - val_accuracy: 0.8749\n",
      "8333/8333 [==============================] - 1s 124us/sample - loss: 0.2938 - accuracy: 0.8848\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=16, batch_size=16, total=  28.8s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=16, batch_size=16 ........\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_8 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 4s 332us/sample - loss: 0.6468 - accuracy: 0.7252 - val_loss: 0.5759 - val_accuracy: 0.7807\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 4s 290us/sample - loss: 0.4932 - accuracy: 0.8330 - val_loss: 0.4427 - val_accuracy: 0.8389\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 4s 288us/sample - loss: 0.3815 - accuracy: 0.8689 - val_loss: 0.3687 - val_accuracy: 0.8686\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 4s 289us/sample - loss: 0.3173 - accuracy: 0.8876 - val_loss: 0.3294 - val_accuracy: 0.8749\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 4s 291us/sample - loss: 0.2767 - accuracy: 0.9030 - val_loss: 0.3072 - val_accuracy: 0.8815\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 4s 283us/sample - loss: 0.2471 - accuracy: 0.9148 - val_loss: 0.2951 - val_accuracy: 0.8836\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 4s 288us/sample - loss: 0.2238 - accuracy: 0.9217 - val_loss: 0.2826 - val_accuracy: 0.8902\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 4s 294us/sample - loss: 0.2044 - accuracy: 0.9287 - val_loss: 0.2760 - val_accuracy: 0.8938\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 4s 298us/sample - loss: 0.1875 - accuracy: 0.9348 - val_loss: 0.2790 - val_accuracy: 0.8902\n",
      "8333/8333 [==============================] - 1s 126us/sample - loss: 0.3003 - accuracy: 0.8721\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=16, batch_size=16, total=  36.6s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=4, batch_size=32 .........\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, None, 4)           32000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_9 ( (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 32,005\n",
      "Trainable params: 32,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13332 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13332/13332 [==============================] - 2s 181us/sample - loss: 0.6862 - accuracy: 0.6655 - val_loss: 0.6763 - val_accuracy: 0.7337\n",
      "Epoch 2/20\n",
      "13332/13332 [==============================] - 2s 143us/sample - loss: 0.6567 - accuracy: 0.7539 - val_loss: 0.6390 - val_accuracy: 0.7582\n",
      "Epoch 3/20\n",
      "13332/13332 [==============================] - 2s 142us/sample - loss: 0.6108 - accuracy: 0.7833 - val_loss: 0.5936 - val_accuracy: 0.7813\n",
      "Epoch 4/20\n",
      "13332/13332 [==============================] - 2s 139us/sample - loss: 0.5617 - accuracy: 0.8048 - val_loss: 0.5504 - val_accuracy: 0.7927\n",
      "Epoch 5/20\n",
      "13332/13332 [==============================] - 2s 135us/sample - loss: 0.5156 - accuracy: 0.8243 - val_loss: 0.5105 - val_accuracy: 0.8113\n",
      "Epoch 6/20\n",
      "13332/13332 [==============================] - 2s 134us/sample - loss: 0.4743 - accuracy: 0.8426 - val_loss: 0.4760 - val_accuracy: 0.8272\n",
      "Epoch 7/20\n",
      "13332/13332 [==============================] - 2s 142us/sample - loss: 0.4385 - accuracy: 0.8553 - val_loss: 0.4461 - val_accuracy: 0.8410\n",
      "Epoch 8/20\n",
      "13332/13332 [==============================] - 2s 140us/sample - loss: 0.4077 - accuracy: 0.8660 - val_loss: 0.4215 - val_accuracy: 0.8482\n",
      "Epoch 9/20\n",
      "13332/13332 [==============================] - 2s 136us/sample - loss: 0.3814 - accuracy: 0.8732 - val_loss: 0.4008 - val_accuracy: 0.8527\n",
      "Epoch 10/20\n",
      "13332/13332 [==============================] - 2s 139us/sample - loss: 0.3589 - accuracy: 0.8814 - val_loss: 0.3829 - val_accuracy: 0.8593\n",
      "Epoch 11/20\n",
      "13332/13332 [==============================] - 2s 133us/sample - loss: 0.3392 - accuracy: 0.8859 - val_loss: 0.3691 - val_accuracy: 0.8617\n",
      "Epoch 12/20\n",
      "13332/13332 [==============================] - 2s 134us/sample - loss: 0.3226 - accuracy: 0.8918 - val_loss: 0.3568 - val_accuracy: 0.8692\n",
      "Epoch 13/20\n",
      "13332/13332 [==============================] - 2s 136us/sample - loss: 0.3074 - accuracy: 0.8959 - val_loss: 0.3471 - val_accuracy: 0.8683\n",
      "8334/8334 [==============================] - 1s 64us/sample - loss: 0.3338 - accuracy: 0.8725\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=4, batch_size=32, total=  25.1s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=4, batch_size=32 .........\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, None, 4)           32000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_10  (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 32,005\n",
      "Trainable params: 32,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 2s 178us/sample - loss: 0.6861 - accuracy: 0.6547 - val_loss: 0.6743 - val_accuracy: 0.7525\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 2s 146us/sample - loss: 0.6535 - accuracy: 0.7649 - val_loss: 0.6340 - val_accuracy: 0.7717\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 2s 136us/sample - loss: 0.6055 - accuracy: 0.7894 - val_loss: 0.5871 - val_accuracy: 0.7894\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 2s 133us/sample - loss: 0.5551 - accuracy: 0.8138 - val_loss: 0.5428 - val_accuracy: 0.8083\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 2s 134us/sample - loss: 0.5083 - accuracy: 0.8312 - val_loss: 0.5030 - val_accuracy: 0.8248\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13333/13333 [==============================] - 2s 133us/sample - loss: 0.4671 - accuracy: 0.8465 - val_loss: 0.4686 - val_accuracy: 0.8353\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 2s 134us/sample - loss: 0.4314 - accuracy: 0.8585 - val_loss: 0.4395 - val_accuracy: 0.8455\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 2s 133us/sample - loss: 0.4009 - accuracy: 0.8685 - val_loss: 0.4155 - val_accuracy: 0.8515\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 2s 135us/sample - loss: 0.3750 - accuracy: 0.8753 - val_loss: 0.3960 - val_accuracy: 0.8542\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 2s 141us/sample - loss: 0.3529 - accuracy: 0.8826 - val_loss: 0.3794 - val_accuracy: 0.8599\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 2s 141us/sample - loss: 0.3339 - accuracy: 0.8892 - val_loss: 0.3648 - val_accuracy: 0.8614\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 2s 134us/sample - loss: 0.3172 - accuracy: 0.8930 - val_loss: 0.3532 - val_accuracy: 0.8653\n",
      "Epoch 13/20\n",
      "13333/13333 [==============================] - 2s 142us/sample - loss: 0.3027 - accuracy: 0.8978 - val_loss: 0.3434 - val_accuracy: 0.8668\n",
      "Epoch 14/20\n",
      "13333/13333 [==============================] - 2s 146us/sample - loss: 0.2894 - accuracy: 0.8999 - val_loss: 0.3354 - val_accuracy: 0.8680\n",
      "Epoch 15/20\n",
      "13333/13333 [==============================] - 2s 142us/sample - loss: 0.2776 - accuracy: 0.9050 - val_loss: 0.3281 - val_accuracy: 0.8704\n",
      "Epoch 16/20\n",
      "13333/13333 [==============================] - 2s 138us/sample - loss: 0.2666 - accuracy: 0.9066 - val_loss: 0.3221 - val_accuracy: 0.8719\n",
      "Epoch 17/20\n",
      "13333/13333 [==============================] - 2s 139us/sample - loss: 0.2566 - accuracy: 0.9098 - val_loss: 0.3169 - val_accuracy: 0.8728\n",
      "Epoch 18/20\n",
      "13333/13333 [==============================] - 2s 141us/sample - loss: 0.2475 - accuracy: 0.9134 - val_loss: 0.3129 - val_accuracy: 0.8734\n",
      "Epoch 19/20\n",
      "13333/13333 [==============================] - 2s 139us/sample - loss: 0.2391 - accuracy: 0.9162 - val_loss: 0.3090 - val_accuracy: 0.8737\n",
      "Epoch 20/20\n",
      "13333/13333 [==============================] - 2s 148us/sample - loss: 0.2309 - accuracy: 0.9191 - val_loss: 0.3064 - val_accuracy: 0.8755\n",
      "8333/8333 [==============================] - 1s 65us/sample - loss: 0.3000 - accuracy: 0.8820\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=4, batch_size=32, total=  38.2s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=4, batch_size=32 .........\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, None, 4)           32000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_11  (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 32,005\n",
      "Trainable params: 32,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 3s 190us/sample - loss: 0.6859 - accuracy: 0.6565 - val_loss: 0.6746 - val_accuracy: 0.7457\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 2s 146us/sample - loss: 0.6542 - accuracy: 0.7559 - val_loss: 0.6339 - val_accuracy: 0.7783\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 2s 142us/sample - loss: 0.6064 - accuracy: 0.7908 - val_loss: 0.5855 - val_accuracy: 0.7951\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 2s 142us/sample - loss: 0.5555 - accuracy: 0.8149 - val_loss: 0.5388 - val_accuracy: 0.8161\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 2s 141us/sample - loss: 0.5079 - accuracy: 0.8342 - val_loss: 0.4983 - val_accuracy: 0.8326\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 2s 141us/sample - loss: 0.4661 - accuracy: 0.8489 - val_loss: 0.4629 - val_accuracy: 0.8440\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 2s 147us/sample - loss: 0.4300 - accuracy: 0.8611 - val_loss: 0.4331 - val_accuracy: 0.8542\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 2s 145us/sample - loss: 0.3991 - accuracy: 0.8714 - val_loss: 0.4082 - val_accuracy: 0.8584\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 2s 141us/sample - loss: 0.3731 - accuracy: 0.8771 - val_loss: 0.3879 - val_accuracy: 0.8650\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 2s 142us/sample - loss: 0.3509 - accuracy: 0.8834 - val_loss: 0.3705 - val_accuracy: 0.8689\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 2s 141us/sample - loss: 0.3317 - accuracy: 0.8884 - val_loss: 0.3554 - val_accuracy: 0.8704\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 2s 141us/sample - loss: 0.3152 - accuracy: 0.8923 - val_loss: 0.3438 - val_accuracy: 0.8698\n",
      "8333/8333 [==============================] - 1s 63us/sample - loss: 0.3566 - accuracy: 0.8620\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=4, batch_size=32, total=  24.1s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=8, batch_size=32 .........\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, None, 8)           64000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_12  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 64,009\n",
      "Trainable params: 64,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13332 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13332/13332 [==============================] - 3s 192us/sample - loss: 0.6817 - accuracy: 0.6693 - val_loss: 0.6629 - val_accuracy: 0.7355\n",
      "Epoch 2/20\n",
      "13332/13332 [==============================] - 2s 152us/sample - loss: 0.6283 - accuracy: 0.7705 - val_loss: 0.5998 - val_accuracy: 0.7741\n",
      "Epoch 3/20\n",
      "13332/13332 [==============================] - 2s 156us/sample - loss: 0.5572 - accuracy: 0.8050 - val_loss: 0.5354 - val_accuracy: 0.8032\n",
      "Epoch 4/20\n",
      "13332/13332 [==============================] - 2s 148us/sample - loss: 0.4921 - accuracy: 0.8332 - val_loss: 0.4818 - val_accuracy: 0.8263\n",
      "Epoch 5/20\n",
      "13332/13332 [==============================] - 2s 143us/sample - loss: 0.4381 - accuracy: 0.8561 - val_loss: 0.4387 - val_accuracy: 0.8452\n",
      "Epoch 6/20\n",
      "13332/13332 [==============================] - 2s 139us/sample - loss: 0.3950 - accuracy: 0.8698 - val_loss: 0.4064 - val_accuracy: 0.8479\n",
      "Epoch 7/20\n",
      "13332/13332 [==============================] - 2s 142us/sample - loss: 0.3611 - accuracy: 0.8810 - val_loss: 0.3811 - val_accuracy: 0.8572\n",
      "Epoch 8/20\n",
      "13332/13332 [==============================] - 2s 141us/sample - loss: 0.3339 - accuracy: 0.8890 - val_loss: 0.3622 - val_accuracy: 0.8635\n",
      "Epoch 9/20\n",
      "13332/13332 [==============================] - 2s 142us/sample - loss: 0.3115 - accuracy: 0.8949 - val_loss: 0.3471 - val_accuracy: 0.8695\n",
      "Epoch 10/20\n",
      "13332/13332 [==============================] - 2s 140us/sample - loss: 0.2924 - accuracy: 0.9005 - val_loss: 0.3353 - val_accuracy: 0.8710\n",
      "Epoch 11/20\n",
      "13332/13332 [==============================] - 2s 142us/sample - loss: 0.2758 - accuracy: 0.9063 - val_loss: 0.3264 - val_accuracy: 0.8719\n",
      "Epoch 12/20\n",
      "13332/13332 [==============================] - 2s 147us/sample - loss: 0.2618 - accuracy: 0.9110 - val_loss: 0.3187 - val_accuracy: 0.8752\n",
      "Epoch 13/20\n",
      "13332/13332 [==============================] - 2s 148us/sample - loss: 0.2484 - accuracy: 0.9150 - val_loss: 0.3130 - val_accuracy: 0.8749\n",
      "8334/8334 [==============================] - 1s 74us/sample - loss: 0.2972 - accuracy: 0.8823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=8, batch_size=32, total=  26.5s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=8, batch_size=32 .........\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, None, 8)           64000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_13  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 64,009\n",
      "Trainable params: 64,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 2s 183us/sample - loss: 0.6809 - accuracy: 0.6837 - val_loss: 0.6610 - val_accuracy: 0.7594\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 2s 148us/sample - loss: 0.6271 - accuracy: 0.7820 - val_loss: 0.5972 - val_accuracy: 0.7888\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 2s 150us/sample - loss: 0.5556 - accuracy: 0.8113 - val_loss: 0.5327 - val_accuracy: 0.8104\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 2s 147us/sample - loss: 0.4895 - accuracy: 0.8380 - val_loss: 0.4783 - val_accuracy: 0.8329\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 2s 139us/sample - loss: 0.4347 - accuracy: 0.8576 - val_loss: 0.4354 - val_accuracy: 0.8461\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 2s 150us/sample - loss: 0.3918 - accuracy: 0.8704 - val_loss: 0.4030 - val_accuracy: 0.8533\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 2s 141us/sample - loss: 0.3578 - accuracy: 0.8813 - val_loss: 0.3784 - val_accuracy: 0.8596\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 2s 147us/sample - loss: 0.3307 - accuracy: 0.8894 - val_loss: 0.3599 - val_accuracy: 0.8632\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 2s 149us/sample - loss: 0.3083 - accuracy: 0.8953 - val_loss: 0.3456 - val_accuracy: 0.8662\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.2896 - accuracy: 0.9004 - val_loss: 0.3343 - val_accuracy: 0.8698\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 2s 150us/sample - loss: 0.2735 - accuracy: 0.9053 - val_loss: 0.3242 - val_accuracy: 0.8716\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 2s 147us/sample - loss: 0.2591 - accuracy: 0.9092 - val_loss: 0.3174 - val_accuracy: 0.8722\n",
      "Epoch 13/20\n",
      "13333/13333 [==============================] - 2s 148us/sample - loss: 0.2467 - accuracy: 0.9137 - val_loss: 0.3110 - val_accuracy: 0.8755\n",
      "Epoch 14/20\n",
      "13333/13333 [==============================] - 2s 156us/sample - loss: 0.2349 - accuracy: 0.9183 - val_loss: 0.3070 - val_accuracy: 0.8743\n",
      "8333/8333 [==============================] - 1s 64us/sample - loss: 0.3008 - accuracy: 0.8818\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=8, batch_size=32, total=  28.8s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=8, batch_size=32 .........\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, None, 8)           64000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_14  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 64,009\n",
      "Trainable params: 64,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 3s 205us/sample - loss: 0.6808 - accuracy: 0.6867 - val_loss: 0.6604 - val_accuracy: 0.7639\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 2s 156us/sample - loss: 0.6256 - accuracy: 0.7788 - val_loss: 0.5932 - val_accuracy: 0.7930\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 2s 154us/sample - loss: 0.5527 - accuracy: 0.8147 - val_loss: 0.5263 - val_accuracy: 0.8221\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 2s 150us/sample - loss: 0.4857 - accuracy: 0.8399 - val_loss: 0.4699 - val_accuracy: 0.8452\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 2s 148us/sample - loss: 0.4307 - accuracy: 0.8603 - val_loss: 0.4276 - val_accuracy: 0.8578\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 2s 148us/sample - loss: 0.3880 - accuracy: 0.8736 - val_loss: 0.3947 - val_accuracy: 0.8593\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 2s 156us/sample - loss: 0.3543 - accuracy: 0.8825 - val_loss: 0.3690 - val_accuracy: 0.8704\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 2s 148us/sample - loss: 0.3273 - accuracy: 0.8878 - val_loss: 0.3492 - val_accuracy: 0.8719\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 2s 148us/sample - loss: 0.3053 - accuracy: 0.8966 - val_loss: 0.3346 - val_accuracy: 0.8731\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 2s 148us/sample - loss: 0.2868 - accuracy: 0.9011 - val_loss: 0.3222 - val_accuracy: 0.8779\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 2s 152us/sample - loss: 0.2707 - accuracy: 0.9052 - val_loss: 0.3112 - val_accuracy: 0.8812\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 2s 146us/sample - loss: 0.2568 - accuracy: 0.9110 - val_loss: 0.3041 - val_accuracy: 0.8818\n",
      "Epoch 13/20\n",
      "13333/13333 [==============================] - 2s 141us/sample - loss: 0.2441 - accuracy: 0.9165 - val_loss: 0.2964 - val_accuracy: 0.8851\n",
      "Epoch 14/20\n",
      "13333/13333 [==============================] - 2s 142us/sample - loss: 0.2325 - accuracy: 0.9209 - val_loss: 0.2909 - val_accuracy: 0.8869\n",
      "Epoch 15/20\n",
      "13333/13333 [==============================] - 2s 145us/sample - loss: 0.2221 - accuracy: 0.9237 - val_loss: 0.2857 - val_accuracy: 0.8878\n",
      "Epoch 16/20\n",
      "13333/13333 [==============================] - 2s 154us/sample - loss: 0.2122 - accuracy: 0.9279 - val_loss: 0.2820 - val_accuracy: 0.8890\n",
      "Epoch 17/20\n",
      "13333/13333 [==============================] - 2s 148us/sample - loss: 0.2031 - accuracy: 0.9318 - val_loss: 0.2795 - val_accuracy: 0.8914\n",
      "Epoch 18/20\n",
      "13333/13333 [==============================] - 2s 144us/sample - loss: 0.1948 - accuracy: 0.9338 - val_loss: 0.2768 - val_accuracy: 0.8926\n",
      "Epoch 19/20\n",
      "13333/13333 [==============================] - 2s 157us/sample - loss: 0.1868 - accuracy: 0.9359 - val_loss: 0.2749 - val_accuracy: 0.8917\n",
      "8333/8333 [==============================] - 1s 67us/sample - loss: 0.2991 - accuracy: 0.8751\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=8, batch_size=32, total=  39.2s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=16, batch_size=32 ........\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_15  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13332 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13332/13332 [==============================] - 3s 201us/sample - loss: 0.6748 - accuracy: 0.6808 - val_loss: 0.6434 - val_accuracy: 0.7546\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13332/13332 [==============================] - 2s 167us/sample - loss: 0.5906 - accuracy: 0.7853 - val_loss: 0.5518 - val_accuracy: 0.7903\n",
      "Epoch 3/20\n",
      "13332/13332 [==============================] - 2s 171us/sample - loss: 0.4950 - accuracy: 0.8304 - val_loss: 0.4720 - val_accuracy: 0.8314\n",
      "Epoch 4/20\n",
      "13332/13332 [==============================] - 2s 163us/sample - loss: 0.4205 - accuracy: 0.8592 - val_loss: 0.4168 - val_accuracy: 0.8506\n",
      "Epoch 5/20\n",
      "13332/13332 [==============================] - 2s 158us/sample - loss: 0.3674 - accuracy: 0.8764 - val_loss: 0.3792 - val_accuracy: 0.8596\n",
      "Epoch 6/20\n",
      "13332/13332 [==============================] - 2s 158us/sample - loss: 0.3291 - accuracy: 0.8879 - val_loss: 0.3555 - val_accuracy: 0.8668\n",
      "Epoch 7/20\n",
      "13332/13332 [==============================] - 2s 158us/sample - loss: 0.3001 - accuracy: 0.8975 - val_loss: 0.3373 - val_accuracy: 0.8695\n",
      "Epoch 8/20\n",
      "13332/13332 [==============================] - 2s 158us/sample - loss: 0.2770 - accuracy: 0.9058 - val_loss: 0.3246 - val_accuracy: 0.8716\n",
      "Epoch 9/20\n",
      "13332/13332 [==============================] - 2s 158us/sample - loss: 0.2576 - accuracy: 0.9122 - val_loss: 0.3149 - val_accuracy: 0.8761\n",
      "Epoch 10/20\n",
      "13332/13332 [==============================] - 2s 160us/sample - loss: 0.2406 - accuracy: 0.9194 - val_loss: 0.3089 - val_accuracy: 0.8770\n",
      "Epoch 11/20\n",
      "13332/13332 [==============================] - 2s 166us/sample - loss: 0.2256 - accuracy: 0.9234 - val_loss: 0.3037 - val_accuracy: 0.8749\n",
      "8334/8334 [==============================] - 1s 71us/sample - loss: 0.2876 - accuracy: 0.8835\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=16, batch_size=32, total=  25.0s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=16, batch_size=32 ........\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_16  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 3s 207us/sample - loss: 0.6743 - accuracy: 0.6863 - val_loss: 0.6423 - val_accuracy: 0.7585\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 2s 166us/sample - loss: 0.5896 - accuracy: 0.7931 - val_loss: 0.5477 - val_accuracy: 0.8011\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 2s 160us/sample - loss: 0.4927 - accuracy: 0.8324 - val_loss: 0.4693 - val_accuracy: 0.8368\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 2s 163us/sample - loss: 0.4174 - accuracy: 0.8610 - val_loss: 0.4136 - val_accuracy: 0.8521\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 2s 162us/sample - loss: 0.3636 - accuracy: 0.8795 - val_loss: 0.3767 - val_accuracy: 0.8569\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 2s 158us/sample - loss: 0.3258 - accuracy: 0.8892 - val_loss: 0.3523 - val_accuracy: 0.8635\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 2s 160us/sample - loss: 0.2969 - accuracy: 0.8963 - val_loss: 0.3352 - val_accuracy: 0.8686\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 2s 157us/sample - loss: 0.2742 - accuracy: 0.9039 - val_loss: 0.3228 - val_accuracy: 0.8716\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 2s 157us/sample - loss: 0.2549 - accuracy: 0.9110 - val_loss: 0.3143 - val_accuracy: 0.8716\n",
      "8333/8333 [==============================] - 1s 67us/sample - loss: 0.3086 - accuracy: 0.8775\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=16, batch_size=32, total=  20.6s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=16, batch_size=32 ........\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_17  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 3s 215us/sample - loss: 0.6731 - accuracy: 0.6943 - val_loss: 0.6401 - val_accuracy: 0.7657\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 2s 158us/sample - loss: 0.5873 - accuracy: 0.7943 - val_loss: 0.5422 - val_accuracy: 0.8122\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 2s 161us/sample - loss: 0.4896 - accuracy: 0.8390 - val_loss: 0.4619 - val_accuracy: 0.8449\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 2s 168us/sample - loss: 0.4135 - accuracy: 0.8640 - val_loss: 0.4047 - val_accuracy: 0.8620\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 2s 160us/sample - loss: 0.3599 - accuracy: 0.8794 - val_loss: 0.3684 - val_accuracy: 0.8668\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 2s 161us/sample - loss: 0.3226 - accuracy: 0.8902 - val_loss: 0.3430 - val_accuracy: 0.8713\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 2s 161us/sample - loss: 0.2939 - accuracy: 0.8992 - val_loss: 0.3229 - val_accuracy: 0.8800\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 2s 159us/sample - loss: 0.2711 - accuracy: 0.9056 - val_loss: 0.3088 - val_accuracy: 0.8836\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 2s 158us/sample - loss: 0.2521 - accuracy: 0.9119 - val_loss: 0.3005 - val_accuracy: 0.8842\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 2s 159us/sample - loss: 0.2359 - accuracy: 0.9171 - val_loss: 0.2931 - val_accuracy: 0.8857\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 2s 156us/sample - loss: 0.2213 - accuracy: 0.9247 - val_loss: 0.2846 - val_accuracy: 0.8890\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 2s 165us/sample - loss: 0.2087 - accuracy: 0.9295 - val_loss: 0.2823 - val_accuracy: 0.8878\n",
      "8333/8333 [==============================] - 1s 66us/sample - loss: 0.3035 - accuracy: 0.8729\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=16, batch_size=32, total=  27.1s\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_18  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 10.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 5s 266us/sample - loss: 0.6189 - accuracy: 0.7307 - val_loss: 0.5161 - val_accuracy: 0.8168\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 5s 243us/sample - loss: 0.4236 - accuracy: 0.8509 - val_loss: 0.3864 - val_accuracy: 0.8564\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 5s 248us/sample - loss: 0.3258 - accuracy: 0.8816 - val_loss: 0.3347 - val_accuracy: 0.8686\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 5s 234us/sample - loss: 0.2774 - accuracy: 0.8977 - val_loss: 0.3087 - val_accuracy: 0.8778\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 5s 234us/sample - loss: 0.2462 - accuracy: 0.9097 - val_loss: 0.2986 - val_accuracy: 0.8810\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 5s 235us/sample - loss: 0.2237 - accuracy: 0.9184 - val_loss: 0.2908 - val_accuracy: 0.8854\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 5s 239us/sample - loss: 0.2050 - accuracy: 0.9248 - val_loss: 0.2849 - val_accuracy: 0.8880\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 5s 235us/sample - loss: 0.1898 - accuracy: 0.9297 - val_loss: 0.2844 - val_accuracy: 0.8884\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 5s 234us/sample - loss: 0.1766 - accuracy: 0.9367 - val_loss: 0.2853 - val_accuracy: 0.8876\n",
      "## length of word index dictionary: 88581\n",
      "## max number of most common words kept: 8000\n",
      "## 25000 review texts are now integer sequences.\n",
      "## Length of first train seq: 512 \n",
      "\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=4, batch_size=16 .........\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, None, 4)           32000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_19  (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 32,005\n",
      "Trainable params: 32,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13332 samples, validate on 3334 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13332/13332 [==============================] - 4s 332us/sample - loss: 0.6833 - accuracy: 0.6304 - val_loss: 0.6694 - val_accuracy: 0.7034\n",
      "Epoch 2/20\n",
      "13332/13332 [==============================] - 4s 290us/sample - loss: 0.6432 - accuracy: 0.7482 - val_loss: 0.6234 - val_accuracy: 0.7070\n",
      "Epoch 3/20\n",
      "13332/13332 [==============================] - 4s 289us/sample - loss: 0.5873 - accuracy: 0.7893 - val_loss: 0.5692 - val_accuracy: 0.7963\n",
      "Epoch 4/20\n",
      "13332/13332 [==============================] - 4s 276us/sample - loss: 0.5320 - accuracy: 0.8174 - val_loss: 0.5218 - val_accuracy: 0.8170\n",
      "Epoch 5/20\n",
      "13332/13332 [==============================] - 4s 277us/sample - loss: 0.4831 - accuracy: 0.8420 - val_loss: 0.4795 - val_accuracy: 0.8341\n",
      "Epoch 6/20\n",
      "13332/13332 [==============================] - 4s 276us/sample - loss: 0.4406 - accuracy: 0.8587 - val_loss: 0.4446 - val_accuracy: 0.8467\n",
      "Epoch 7/20\n",
      "13332/13332 [==============================] - 4s 294us/sample - loss: 0.4049 - accuracy: 0.8711 - val_loss: 0.4158 - val_accuracy: 0.8527\n",
      "Epoch 8/20\n",
      "13332/13332 [==============================] - 4s 279us/sample - loss: 0.3747 - accuracy: 0.8780 - val_loss: 0.3908 - val_accuracy: 0.8614\n",
      "Epoch 9/20\n",
      "13332/13332 [==============================] - 4s 279us/sample - loss: 0.3494 - accuracy: 0.8858 - val_loss: 0.3718 - val_accuracy: 0.8683\n",
      "Epoch 10/20\n",
      "13332/13332 [==============================] - 4s 275us/sample - loss: 0.3276 - accuracy: 0.8930 - val_loss: 0.3552 - val_accuracy: 0.8713\n",
      "Epoch 11/20\n",
      "13332/13332 [==============================] - 4s 286us/sample - loss: 0.3087 - accuracy: 0.8976 - val_loss: 0.3423 - val_accuracy: 0.8737\n",
      "Epoch 12/20\n",
      "13332/13332 [==============================] - 4s 278us/sample - loss: 0.2928 - accuracy: 0.9008 - val_loss: 0.3312 - val_accuracy: 0.8767\n",
      "Epoch 13/20\n",
      "13332/13332 [==============================] - 4s 278us/sample - loss: 0.2783 - accuracy: 0.9064 - val_loss: 0.3233 - val_accuracy: 0.8770\n",
      "Epoch 14/20\n",
      "13332/13332 [==============================] - 4s 277us/sample - loss: 0.2652 - accuracy: 0.9107 - val_loss: 0.3150 - val_accuracy: 0.8773\n",
      "Epoch 15/20\n",
      "13332/13332 [==============================] - 4s 277us/sample - loss: 0.2535 - accuracy: 0.9152 - val_loss: 0.3104 - val_accuracy: 0.8803\n",
      "Epoch 16/20\n",
      "13332/13332 [==============================] - 4s 285us/sample - loss: 0.2431 - accuracy: 0.9194 - val_loss: 0.3050 - val_accuracy: 0.8812\n",
      "Epoch 17/20\n",
      "13332/13332 [==============================] - 4s 276us/sample - loss: 0.2333 - accuracy: 0.9236 - val_loss: 0.3026 - val_accuracy: 0.8791\n",
      "8334/8334 [==============================] - 1s 123us/sample - loss: 0.2895 - accuracy: 0.8892\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=4, batch_size=16, total= 1.1min\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=4, batch_size=16 .........\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, None, 4)           32000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_20  (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 32,005\n",
      "Trainable params: 32,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13333/13333 [==============================] - 4s 322us/sample - loss: 0.6850 - accuracy: 0.6224 - val_loss: 0.6735 - val_accuracy: 0.6632\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 4s 286us/sample - loss: 0.6498 - accuracy: 0.7361 - val_loss: 0.6282 - val_accuracy: 0.7726\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 4s 278us/sample - loss: 0.5947 - accuracy: 0.7921 - val_loss: 0.5749 - val_accuracy: 0.7954\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 4s 277us/sample - loss: 0.5382 - accuracy: 0.8176 - val_loss: 0.5258 - val_accuracy: 0.8188\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 4s 275us/sample - loss: 0.4872 - accuracy: 0.8399 - val_loss: 0.4831 - val_accuracy: 0.8356\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 4s 274us/sample - loss: 0.4439 - accuracy: 0.8551 - val_loss: 0.4483 - val_accuracy: 0.8416\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 4s 282us/sample - loss: 0.4068 - accuracy: 0.8672 - val_loss: 0.4170 - val_accuracy: 0.8572\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 4s 275us/sample - loss: 0.3759 - accuracy: 0.8760 - val_loss: 0.3927 - val_accuracy: 0.8617\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 4s 275us/sample - loss: 0.3497 - accuracy: 0.8847 - val_loss: 0.3732 - val_accuracy: 0.8644\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 4s 277us/sample - loss: 0.3279 - accuracy: 0.8887 - val_loss: 0.3583 - val_accuracy: 0.8689\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 4s 284us/sample - loss: 0.3093 - accuracy: 0.8977 - val_loss: 0.3424 - val_accuracy: 0.8743\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 4s 275us/sample - loss: 0.2929 - accuracy: 0.9009 - val_loss: 0.3326 - val_accuracy: 0.8749\n",
      "Epoch 13/20\n",
      "13333/13333 [==============================] - 4s 280us/sample - loss: 0.2792 - accuracy: 0.9052 - val_loss: 0.3228 - val_accuracy: 0.8803\n",
      "Epoch 14/20\n",
      "13333/13333 [==============================] - 4s 277us/sample - loss: 0.2660 - accuracy: 0.9089 - val_loss: 0.3168 - val_accuracy: 0.8782\n",
      "8333/8333 [==============================] - 1s 127us/sample - loss: 0.3174 - accuracy: 0.8787\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=4, batch_size=16, total=  53.7s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=4, batch_size=16 .........\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, None, 4)           32000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_21  (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 32,005\n",
      "Trainable params: 32,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 4s 327us/sample - loss: 0.6841 - accuracy: 0.6506 - val_loss: 0.6686 - val_accuracy: 0.6551\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 4s 276us/sample - loss: 0.6402 - accuracy: 0.7484 - val_loss: 0.6129 - val_accuracy: 0.7807\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 4s 275us/sample - loss: 0.5803 - accuracy: 0.8035 - val_loss: 0.5564 - val_accuracy: 0.8137\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 4s 280us/sample - loss: 0.5226 - accuracy: 0.8297 - val_loss: 0.5061 - val_accuracy: 0.8338\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 4s 281us/sample - loss: 0.4719 - accuracy: 0.8503 - val_loss: 0.4663 - val_accuracy: 0.8485\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 4s 275us/sample - loss: 0.4294 - accuracy: 0.8652 - val_loss: 0.4305 - val_accuracy: 0.8560\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 4s 275us/sample - loss: 0.3935 - accuracy: 0.8735 - val_loss: 0.4013 - val_accuracy: 0.8671\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 4s 275us/sample - loss: 0.3639 - accuracy: 0.8828 - val_loss: 0.3782 - val_accuracy: 0.8716\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 4s 276us/sample - loss: 0.3391 - accuracy: 0.8911 - val_loss: 0.3609 - val_accuracy: 0.8725\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 4s 282us/sample - loss: 0.3180 - accuracy: 0.8951 - val_loss: 0.3454 - val_accuracy: 0.8770\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 4s 274us/sample - loss: 0.3001 - accuracy: 0.8993 - val_loss: 0.3320 - val_accuracy: 0.8779\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 4s 275us/sample - loss: 0.2847 - accuracy: 0.9051 - val_loss: 0.3240 - val_accuracy: 0.8827\n",
      "Epoch 13/20\n",
      "13333/13333 [==============================] - 4s 275us/sample - loss: 0.2707 - accuracy: 0.9098 - val_loss: 0.3129 - val_accuracy: 0.8839\n",
      "Epoch 14/20\n",
      "13333/13333 [==============================] - 4s 281us/sample - loss: 0.2582 - accuracy: 0.9143 - val_loss: 0.3062 - val_accuracy: 0.8863\n",
      "Epoch 15/20\n",
      "13333/13333 [==============================] - 4s 278us/sample - loss: 0.2471 - accuracy: 0.9169 - val_loss: 0.3009 - val_accuracy: 0.8842\n",
      "8333/8333 [==============================] - 1s 131us/sample - loss: 0.3137 - accuracy: 0.8751\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=4, batch_size=16, total=  57.3s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=8, batch_size=16 .........\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, None, 8)           64000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_22  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 64,009\n",
      "Trainable params: 64,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13332 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13332/13332 [==============================] - 5s 352us/sample - loss: 0.6808 - accuracy: 0.6308 - val_loss: 0.6597 - val_accuracy: 0.7223\n",
      "Epoch 2/20\n",
      "13332/13332 [==============================] - 4s 296us/sample - loss: 0.6189 - accuracy: 0.7624 - val_loss: 0.5908 - val_accuracy: 0.7208\n",
      "8334/8334 [==============================] - 1s 136us/sample - loss: 0.5860 - accuracy: 0.7307\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=8, batch_size=16, total=   9.9s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=8, batch_size=16 .........\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, None, 8)           64000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_23  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 64,009\n",
      "Trainable params: 64,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 4s 337us/sample - loss: 0.6833 - accuracy: 0.6338 - val_loss: 0.6665 - val_accuracy: 0.6674\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 4s 300us/sample - loss: 0.6294 - accuracy: 0.7508 - val_loss: 0.5969 - val_accuracy: 0.7774\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13333/13333 [==============================] - 4s 301us/sample - loss: 0.5497 - accuracy: 0.8081 - val_loss: 0.5249 - val_accuracy: 0.8194\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 4s 293us/sample - loss: 0.4779 - accuracy: 0.8384 - val_loss: 0.4661 - val_accuracy: 0.8371\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 4s 288us/sample - loss: 0.4199 - accuracy: 0.8605 - val_loss: 0.4208 - val_accuracy: 0.8557\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 4s 289us/sample - loss: 0.3760 - accuracy: 0.8747 - val_loss: 0.3898 - val_accuracy: 0.8566\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 4s 294us/sample - loss: 0.3417 - accuracy: 0.8854 - val_loss: 0.3631 - val_accuracy: 0.8665\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 4s 293us/sample - loss: 0.3149 - accuracy: 0.8936 - val_loss: 0.3442 - val_accuracy: 0.8710\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 4s 287us/sample - loss: 0.2927 - accuracy: 0.8990 - val_loss: 0.3312 - val_accuracy: 0.8716\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 4s 289us/sample - loss: 0.2745 - accuracy: 0.9050 - val_loss: 0.3226 - val_accuracy: 0.8743\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 4s 288us/sample - loss: 0.2590 - accuracy: 0.9110 - val_loss: 0.3102 - val_accuracy: 0.8821\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 4s 295us/sample - loss: 0.2453 - accuracy: 0.9150 - val_loss: 0.3058 - val_accuracy: 0.8791\n",
      "8333/8333 [==============================] - 1s 126us/sample - loss: 0.3063 - accuracy: 0.8820\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=8, batch_size=16, total=  48.6s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=8, batch_size=16 .........\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, None, 8)           64000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_24  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 64,009\n",
      "Trainable params: 64,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 4s 337us/sample - loss: 0.6832 - accuracy: 0.6540 - val_loss: 0.6658 - val_accuracy: 0.6500\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 4s 297us/sample - loss: 0.6284 - accuracy: 0.7558 - val_loss: 0.5912 - val_accuracy: 0.7801\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 4s 289us/sample - loss: 0.5475 - accuracy: 0.8133 - val_loss: 0.5172 - val_accuracy: 0.8257\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 4s 294us/sample - loss: 0.4744 - accuracy: 0.8443 - val_loss: 0.4574 - val_accuracy: 0.8479\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 4s 290us/sample - loss: 0.4161 - accuracy: 0.8675 - val_loss: 0.4155 - val_accuracy: 0.8614\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 4s 288us/sample - loss: 0.3721 - accuracy: 0.8792 - val_loss: 0.3819 - val_accuracy: 0.8653\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 4s 288us/sample - loss: 0.3379 - accuracy: 0.8878 - val_loss: 0.3555 - val_accuracy: 0.8710\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 4s 295us/sample - loss: 0.3114 - accuracy: 0.8956 - val_loss: 0.3366 - val_accuracy: 0.8776\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 4s 288us/sample - loss: 0.2898 - accuracy: 0.9017 - val_loss: 0.3246 - val_accuracy: 0.8818\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 4s 287us/sample - loss: 0.2715 - accuracy: 0.9078 - val_loss: 0.3130 - val_accuracy: 0.8842\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 4s 286us/sample - loss: 0.2560 - accuracy: 0.9127 - val_loss: 0.3027 - val_accuracy: 0.8875\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 4s 298us/sample - loss: 0.2427 - accuracy: 0.9177 - val_loss: 0.2996 - val_accuracy: 0.8884\n",
      "Epoch 13/20\n",
      "13333/13333 [==============================] - 4s 288us/sample - loss: 0.2303 - accuracy: 0.9229 - val_loss: 0.2908 - val_accuracy: 0.8878\n",
      "8333/8333 [==============================] - 1s 129us/sample - loss: 0.3053 - accuracy: 0.8787\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=8, batch_size=16, total=  52.2s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=16, batch_size=16 ........\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_25  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13332 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13332/13332 [==============================] - 5s 364us/sample - loss: 0.6732 - accuracy: 0.6556 - val_loss: 0.6383 - val_accuracy: 0.7588\n",
      "Epoch 2/20\n",
      "13332/13332 [==============================] - 4s 325us/sample - loss: 0.5786 - accuracy: 0.7871 - val_loss: 0.5431 - val_accuracy: 0.7504\n",
      "8334/8334 [==============================] - 1s 146us/sample - loss: 0.5359 - accuracy: 0.7660\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=16, batch_size=16, total=  10.6s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=16, batch_size=16 ........\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_26  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 5s 354us/sample - loss: 0.6733 - accuracy: 0.6446 - val_loss: 0.6377 - val_accuracy: 0.6971\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 4s 313us/sample - loss: 0.5752 - accuracy: 0.7850 - val_loss: 0.5313 - val_accuracy: 0.7972\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 4s 308us/sample - loss: 0.4699 - accuracy: 0.8383 - val_loss: 0.4474 - val_accuracy: 0.8404\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 4s 316us/sample - loss: 0.3940 - accuracy: 0.8678 - val_loss: 0.3921 - val_accuracy: 0.8641\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 4s 311us/sample - loss: 0.3421 - accuracy: 0.8861 - val_loss: 0.3568 - val_accuracy: 0.8710\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 4s 310us/sample - loss: 0.3064 - accuracy: 0.8945 - val_loss: 0.3367 - val_accuracy: 0.8743\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 4s 308us/sample - loss: 0.2791 - accuracy: 0.9023 - val_loss: 0.3190 - val_accuracy: 0.8761\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 4s 314us/sample - loss: 0.2576 - accuracy: 0.9108 - val_loss: 0.3069 - val_accuracy: 0.8860\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13333/13333 [==============================] - 4s 308us/sample - loss: 0.2392 - accuracy: 0.9173 - val_loss: 0.3018 - val_accuracy: 0.8803\n",
      "8333/8333 [==============================] - 1s 132us/sample - loss: 0.3028 - accuracy: 0.8837\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=16, batch_size=16, total=  39.1s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=16, batch_size=16 ........\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_27  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 5s 366us/sample - loss: 0.6741 - accuracy: 0.6590 - val_loss: 0.6389 - val_accuracy: 0.6878\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 4s 320us/sample - loss: 0.5775 - accuracy: 0.7929 - val_loss: 0.5285 - val_accuracy: 0.7990\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 4s 309us/sample - loss: 0.4712 - accuracy: 0.8449 - val_loss: 0.4437 - val_accuracy: 0.8488\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 4s 311us/sample - loss: 0.3936 - accuracy: 0.8711 - val_loss: 0.3880 - val_accuracy: 0.8689\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 4s 309us/sample - loss: 0.3415 - accuracy: 0.8862 - val_loss: 0.3561 - val_accuracy: 0.8722\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 4s 310us/sample - loss: 0.3050 - accuracy: 0.8982 - val_loss: 0.3320 - val_accuracy: 0.8782\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 4s 307us/sample - loss: 0.2775 - accuracy: 0.9042 - val_loss: 0.3134 - val_accuracy: 0.8830\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 4s 307us/sample - loss: 0.2560 - accuracy: 0.9110 - val_loss: 0.3003 - val_accuracy: 0.8896\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 4s 310us/sample - loss: 0.2379 - accuracy: 0.9182 - val_loss: 0.2948 - val_accuracy: 0.8908\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 4s 315us/sample - loss: 0.2219 - accuracy: 0.9243 - val_loss: 0.2877 - val_accuracy: 0.8923\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 4s 310us/sample - loss: 0.2081 - accuracy: 0.9294 - val_loss: 0.2808 - val_accuracy: 0.8950\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 4s 309us/sample - loss: 0.1959 - accuracy: 0.9335 - val_loss: 0.2827 - val_accuracy: 0.8947\n",
      "8333/8333 [==============================] - 1s 134us/sample - loss: 0.2974 - accuracy: 0.8810\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=16, batch_size=16, total=  51.7s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=4, batch_size=32 .........\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (None, None, 4)           32000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_28  (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 32,005\n",
      "Trainable params: 32,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13332 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13332/13332 [==============================] - 3s 212us/sample - loss: 0.6886 - accuracy: 0.6133 - val_loss: 0.6825 - val_accuracy: 0.6569\n",
      "Epoch 2/20\n",
      "13332/13332 [==============================] - 2s 168us/sample - loss: 0.6705 - accuracy: 0.7114 - val_loss: 0.6602 - val_accuracy: 0.7040\n",
      "Epoch 3/20\n",
      "13332/13332 [==============================] - 2s 153us/sample - loss: 0.6410 - accuracy: 0.7501 - val_loss: 0.6297 - val_accuracy: 0.7636\n",
      "Epoch 4/20\n",
      "13332/13332 [==============================] - 2s 154us/sample - loss: 0.6061 - accuracy: 0.7843 - val_loss: 0.5976 - val_accuracy: 0.7675\n",
      "Epoch 5/20\n",
      "13332/13332 [==============================] - 2s 152us/sample - loss: 0.5709 - accuracy: 0.8041 - val_loss: 0.5659 - val_accuracy: 0.7921\n",
      "Epoch 6/20\n",
      "13332/13332 [==============================] - 2s 154us/sample - loss: 0.5372 - accuracy: 0.8183 - val_loss: 0.5364 - val_accuracy: 0.8071\n",
      "Epoch 7/20\n",
      "13332/13332 [==============================] - 2s 154us/sample - loss: 0.5059 - accuracy: 0.8332 - val_loss: 0.5088 - val_accuracy: 0.8215\n",
      "Epoch 8/20\n",
      "13332/13332 [==============================] - 2s 153us/sample - loss: 0.4773 - accuracy: 0.8450 - val_loss: 0.4841 - val_accuracy: 0.8308\n",
      "Epoch 9/20\n",
      "13332/13332 [==============================] - 2s 153us/sample - loss: 0.4511 - accuracy: 0.8558 - val_loss: 0.4614 - val_accuracy: 0.8392\n",
      "Epoch 10/20\n",
      "13332/13332 [==============================] - 2s 162us/sample - loss: 0.4273 - accuracy: 0.8653 - val_loss: 0.4404 - val_accuracy: 0.8506\n",
      "Epoch 11/20\n",
      "13332/13332 [==============================] - 2s 153us/sample - loss: 0.4059 - accuracy: 0.8726 - val_loss: 0.4228 - val_accuracy: 0.8530\n",
      "Epoch 12/20\n",
      "13332/13332 [==============================] - 2s 153us/sample - loss: 0.3871 - accuracy: 0.8765 - val_loss: 0.4067 - val_accuracy: 0.8581\n",
      "Epoch 13/20\n",
      "13332/13332 [==============================] - 2s 154us/sample - loss: 0.3696 - accuracy: 0.8811 - val_loss: 0.3930 - val_accuracy: 0.8620\n",
      "Epoch 14/20\n",
      "13332/13332 [==============================] - 2s 153us/sample - loss: 0.3537 - accuracy: 0.8870 - val_loss: 0.3800 - val_accuracy: 0.8650\n",
      "Epoch 15/20\n",
      "13332/13332 [==============================] - 2s 153us/sample - loss: 0.3398 - accuracy: 0.8912 - val_loss: 0.3697 - val_accuracy: 0.8671\n",
      "Epoch 16/20\n",
      "13332/13332 [==============================] - 2s 156us/sample - loss: 0.3269 - accuracy: 0.8939 - val_loss: 0.3608 - val_accuracy: 0.8677\n",
      "Epoch 17/20\n",
      "13332/13332 [==============================] - 2s 154us/sample - loss: 0.3154 - accuracy: 0.8975 - val_loss: 0.3523 - val_accuracy: 0.8710\n",
      "Epoch 18/20\n",
      "13332/13332 [==============================] - 2s 161us/sample - loss: 0.3043 - accuracy: 0.8998 - val_loss: 0.3437 - val_accuracy: 0.8755\n",
      "Epoch 19/20\n",
      "13332/13332 [==============================] - 2s 154us/sample - loss: 0.2941 - accuracy: 0.9050 - val_loss: 0.3362 - val_accuracy: 0.8785\n",
      "Epoch 20/20\n",
      "13332/13332 [==============================] - 2s 154us/sample - loss: 0.2849 - accuracy: 0.9056 - val_loss: 0.3301 - val_accuracy: 0.8758\n",
      "8334/8334 [==============================] - 1s 67us/sample - loss: 0.3180 - accuracy: 0.8823\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=4, batch_size=32, total=  42.9s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=4, batch_size=32 .........\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, None, 4)           32000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_29  (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 32,005\n",
      "Trainable params: 32,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13333/13333 [==============================] - 3s 197us/sample - loss: 0.6898 - accuracy: 0.5897 - val_loss: 0.6844 - val_accuracy: 0.7445\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 2s 162us/sample - loss: 0.6725 - accuracy: 0.7095 - val_loss: 0.6609 - val_accuracy: 0.7540\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 2s 161us/sample - loss: 0.6416 - accuracy: 0.7657 - val_loss: 0.6287 - val_accuracy: 0.7663\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 2s 162us/sample - loss: 0.6052 - accuracy: 0.7901 - val_loss: 0.5951 - val_accuracy: 0.7792\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 2s 161us/sample - loss: 0.5686 - accuracy: 0.8045 - val_loss: 0.5630 - val_accuracy: 0.7954\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.5345 - accuracy: 0.8192 - val_loss: 0.5330 - val_accuracy: 0.8134\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.5026 - accuracy: 0.8327 - val_loss: 0.5052 - val_accuracy: 0.8278\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.4734 - accuracy: 0.8466 - val_loss: 0.4803 - val_accuracy: 0.8347\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 2s 152us/sample - loss: 0.4468 - accuracy: 0.8540 - val_loss: 0.4579 - val_accuracy: 0.8431\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 2s 152us/sample - loss: 0.4230 - accuracy: 0.8642 - val_loss: 0.4381 - val_accuracy: 0.8518\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.4016 - accuracy: 0.8710 - val_loss: 0.4193 - val_accuracy: 0.8578\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 2s 154us/sample - loss: 0.3825 - accuracy: 0.8780 - val_loss: 0.4035 - val_accuracy: 0.8617\n",
      "Epoch 13/20\n",
      "13333/13333 [==============================] - 2s 160us/sample - loss: 0.3656 - accuracy: 0.8828 - val_loss: 0.3895 - val_accuracy: 0.8644\n",
      "Epoch 14/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.3500 - accuracy: 0.8858 - val_loss: 0.3778 - val_accuracy: 0.8623\n",
      "8333/8333 [==============================] - 1s 67us/sample - loss: 0.3759 - accuracy: 0.8674\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=4, batch_size=32, total=  30.4s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=4, batch_size=32 .........\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, None, 4)           32000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_30  (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 32,005\n",
      "Trainable params: 32,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 3s 206us/sample - loss: 0.6891 - accuracy: 0.6267 - val_loss: 0.6831 - val_accuracy: 0.6554\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 2s 161us/sample - loss: 0.6722 - accuracy: 0.6954 - val_loss: 0.6600 - val_accuracy: 0.7744\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 2s 161us/sample - loss: 0.6432 - accuracy: 0.7738 - val_loss: 0.6280 - val_accuracy: 0.7897\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 2s 157us/sample - loss: 0.6078 - accuracy: 0.7954 - val_loss: 0.5934 - val_accuracy: 0.8032\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 2s 156us/sample - loss: 0.5712 - accuracy: 0.8114 - val_loss: 0.5612 - val_accuracy: 0.8125\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 2s 160us/sample - loss: 0.5367 - accuracy: 0.8285 - val_loss: 0.5291 - val_accuracy: 0.8227\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.5043 - accuracy: 0.8388 - val_loss: 0.5009 - val_accuracy: 0.8362\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 2s 154us/sample - loss: 0.4744 - accuracy: 0.8515 - val_loss: 0.4753 - val_accuracy: 0.8440\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 2s 154us/sample - loss: 0.4475 - accuracy: 0.8608 - val_loss: 0.4528 - val_accuracy: 0.8560\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 2s 154us/sample - loss: 0.4232 - accuracy: 0.8699 - val_loss: 0.4328 - val_accuracy: 0.8605\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.4015 - accuracy: 0.8749 - val_loss: 0.4147 - val_accuracy: 0.8641\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 2s 152us/sample - loss: 0.3823 - accuracy: 0.8808 - val_loss: 0.3997 - val_accuracy: 0.8665\n",
      "Epoch 13/20\n",
      "13333/13333 [==============================] - 2s 160us/sample - loss: 0.3648 - accuracy: 0.8852 - val_loss: 0.3850 - val_accuracy: 0.8698\n",
      "Epoch 14/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.3491 - accuracy: 0.8895 - val_loss: 0.3730 - val_accuracy: 0.8704\n",
      "Epoch 15/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.3350 - accuracy: 0.8922 - val_loss: 0.3616 - val_accuracy: 0.8737\n",
      "Epoch 16/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.3221 - accuracy: 0.8949 - val_loss: 0.3521 - val_accuracy: 0.8749\n",
      "Epoch 17/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.3104 - accuracy: 0.8983 - val_loss: 0.3437 - val_accuracy: 0.8773\n",
      "Epoch 18/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.2997 - accuracy: 0.9018 - val_loss: 0.3359 - val_accuracy: 0.8782\n",
      "Epoch 19/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.2898 - accuracy: 0.9046 - val_loss: 0.3289 - val_accuracy: 0.8809\n",
      "Epoch 20/20\n",
      "13333/13333 [==============================] - 2s 153us/sample - loss: 0.2806 - accuracy: 0.9076 - val_loss: 0.3225 - val_accuracy: 0.8824\n",
      "8333/8333 [==============================] - 1s 65us/sample - loss: 0.3327 - accuracy: 0.8733\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=4, batch_size=32, total=  42.7s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=8, batch_size=32 .........\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_31 (Embedding)     (None, None, 8)           64000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_31  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 64,009\n",
      "Trainable params: 64,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13332 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13332/13332 [==============================] - 3s 214us/sample - loss: 0.6880 - accuracy: 0.6211 - val_loss: 0.6795 - val_accuracy: 0.6680\n",
      "Epoch 2/20\n",
      "13332/13332 [==============================] - 2s 170us/sample - loss: 0.6600 - accuracy: 0.7222 - val_loss: 0.6425 - val_accuracy: 0.7088\n",
      "Epoch 3/20\n",
      "13332/13332 [==============================] - 2s 169us/sample - loss: 0.6124 - accuracy: 0.7718 - val_loss: 0.5951 - val_accuracy: 0.7810\n",
      "Epoch 4/20\n",
      "13332/13332 [==============================] - 2s 170us/sample - loss: 0.5614 - accuracy: 0.8032 - val_loss: 0.5504 - val_accuracy: 0.8005\n",
      "Epoch 5/20\n",
      "13332/13332 [==============================] - 2s 169us/sample - loss: 0.5146 - accuracy: 0.8248 - val_loss: 0.5098 - val_accuracy: 0.8191\n",
      "Epoch 6/20\n",
      "13332/13332 [==============================] - 2s 160us/sample - loss: 0.4729 - accuracy: 0.8432 - val_loss: 0.4751 - val_accuracy: 0.8320\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13332/13332 [==============================] - 2s 160us/sample - loss: 0.4367 - accuracy: 0.8583 - val_loss: 0.4444 - val_accuracy: 0.8437\n",
      "Epoch 8/20\n",
      "13332/13332 [==============================] - 2s 168us/sample - loss: 0.4060 - accuracy: 0.8685 - val_loss: 0.4188 - val_accuracy: 0.8551\n",
      "Epoch 9/20\n",
      "13332/13332 [==============================] - 2s 158us/sample - loss: 0.3794 - accuracy: 0.8761 - val_loss: 0.3973 - val_accuracy: 0.8590\n",
      "Epoch 10/20\n",
      "13332/13332 [==============================] - 2s 159us/sample - loss: 0.3567 - accuracy: 0.8850 - val_loss: 0.3792 - val_accuracy: 0.8695\n",
      "Epoch 11/20\n",
      "13332/13332 [==============================] - 2s 159us/sample - loss: 0.3371 - accuracy: 0.8903 - val_loss: 0.3647 - val_accuracy: 0.8677\n",
      "8334/8334 [==============================] - 1s 71us/sample - loss: 0.3530 - accuracy: 0.8733\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=8, batch_size=32, total=  25.5s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=8, batch_size=32 .........\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_32 (Embedding)     (None, None, 8)           64000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_32  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 64,009\n",
      "Trainable params: 64,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 3s 203us/sample - loss: 0.6871 - accuracy: 0.6109 - val_loss: 0.6776 - val_accuracy: 0.6788\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 2s 169us/sample - loss: 0.6573 - accuracy: 0.7246 - val_loss: 0.6382 - val_accuracy: 0.7684\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 2s 174us/sample - loss: 0.6080 - accuracy: 0.7832 - val_loss: 0.5896 - val_accuracy: 0.7831\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 2s 170us/sample - loss: 0.5557 - accuracy: 0.8106 - val_loss: 0.5435 - val_accuracy: 0.8083\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 2s 169us/sample - loss: 0.5073 - accuracy: 0.8308 - val_loss: 0.5027 - val_accuracy: 0.8287\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 2s 169us/sample - loss: 0.4656 - accuracy: 0.8483 - val_loss: 0.4679 - val_accuracy: 0.8356\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 2s 168us/sample - loss: 0.4291 - accuracy: 0.8591 - val_loss: 0.4376 - val_accuracy: 0.8506\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 2s 168us/sample - loss: 0.3983 - accuracy: 0.8714 - val_loss: 0.4128 - val_accuracy: 0.8602\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 2s 169us/sample - loss: 0.3720 - accuracy: 0.8795 - val_loss: 0.3921 - val_accuracy: 0.8620\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 2s 171us/sample - loss: 0.3499 - accuracy: 0.8849 - val_loss: 0.3753 - val_accuracy: 0.8647\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 2s 166us/sample - loss: 0.3307 - accuracy: 0.8909 - val_loss: 0.3600 - val_accuracy: 0.8695\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 2s 159us/sample - loss: 0.3141 - accuracy: 0.8961 - val_loss: 0.3485 - val_accuracy: 0.8707\n",
      "Epoch 13/20\n",
      "13333/13333 [==============================] - 2s 161us/sample - loss: 0.2998 - accuracy: 0.9011 - val_loss: 0.3378 - val_accuracy: 0.8746\n",
      "Epoch 14/20\n",
      "13333/13333 [==============================] - 2s 158us/sample - loss: 0.2862 - accuracy: 0.9032 - val_loss: 0.3307 - val_accuracy: 0.8737\n",
      "8333/8333 [==============================] - 1s 70us/sample - loss: 0.3307 - accuracy: 0.8758\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=8, batch_size=32, total=  32.4s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=8, batch_size=32 .........\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_33 (Embedding)     (None, None, 8)           64000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_33  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 64,009\n",
      "Trainable params: 64,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 3s 211us/sample - loss: 0.6870 - accuracy: 0.6427 - val_loss: 0.6774 - val_accuracy: 0.6650\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 2s 169us/sample - loss: 0.6583 - accuracy: 0.7188 - val_loss: 0.6375 - val_accuracy: 0.7831\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 2s 171us/sample - loss: 0.6106 - accuracy: 0.7867 - val_loss: 0.5882 - val_accuracy: 0.8029\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 2s 160us/sample - loss: 0.5584 - accuracy: 0.8134 - val_loss: 0.5404 - val_accuracy: 0.8179\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 2s 160us/sample - loss: 0.5096 - accuracy: 0.8366 - val_loss: 0.5002 - val_accuracy: 0.8335\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 2s 159us/sample - loss: 0.4672 - accuracy: 0.8521 - val_loss: 0.4632 - val_accuracy: 0.8482\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 2s 159us/sample - loss: 0.4301 - accuracy: 0.8633 - val_loss: 0.4331 - val_accuracy: 0.8587\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 2s 164us/sample - loss: 0.3987 - accuracy: 0.8767 - val_loss: 0.4080 - val_accuracy: 0.8662\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 2s 166us/sample - loss: 0.3723 - accuracy: 0.8812 - val_loss: 0.3880 - val_accuracy: 0.8674\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 2s 160us/sample - loss: 0.3497 - accuracy: 0.8872 - val_loss: 0.3711 - val_accuracy: 0.8722\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 2s 167us/sample - loss: 0.3304 - accuracy: 0.8928 - val_loss: 0.3562 - val_accuracy: 0.8731\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 2s 159us/sample - loss: 0.3140 - accuracy: 0.8969 - val_loss: 0.3454 - val_accuracy: 0.8749\n",
      "Epoch 13/20\n",
      "13333/13333 [==============================] - 2s 161us/sample - loss: 0.2989 - accuracy: 0.9011 - val_loss: 0.3334 - val_accuracy: 0.8797\n",
      "Epoch 14/20\n",
      "13333/13333 [==============================] - 2s 161us/sample - loss: 0.2856 - accuracy: 0.9060 - val_loss: 0.3252 - val_accuracy: 0.8809\n",
      "Epoch 15/20\n",
      "13333/13333 [==============================] - 2s 162us/sample - loss: 0.2739 - accuracy: 0.9098 - val_loss: 0.3169 - val_accuracy: 0.8824\n",
      "Epoch 16/20\n",
      "13333/13333 [==============================] - 2s 160us/sample - loss: 0.2629 - accuracy: 0.9113 - val_loss: 0.3104 - val_accuracy: 0.8881\n",
      "Epoch 17/20\n",
      "13333/13333 [==============================] - 2s 160us/sample - loss: 0.2528 - accuracy: 0.9149 - val_loss: 0.3053 - val_accuracy: 0.8842\n",
      "8333/8333 [==============================] - 1s 65us/sample - loss: 0.3163 - accuracy: 0.8759\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=8, batch_size=32, total=  38.2s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=16, batch_size=32 ........\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_34  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13332 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13332/13332 [==============================] - 3s 217us/sample - loss: 0.6835 - accuracy: 0.6346 - val_loss: 0.6684 - val_accuracy: 0.6728\n",
      "Epoch 2/20\n",
      "13332/13332 [==============================] - 2s 181us/sample - loss: 0.6358 - accuracy: 0.7478 - val_loss: 0.6103 - val_accuracy: 0.7154\n",
      "Epoch 3/20\n",
      "13332/13332 [==============================] - 2s 182us/sample - loss: 0.5658 - accuracy: 0.7967 - val_loss: 0.5439 - val_accuracy: 0.8056\n",
      "Epoch 4/20\n",
      "13332/13332 [==============================] - 2s 177us/sample - loss: 0.4996 - accuracy: 0.8308 - val_loss: 0.4892 - val_accuracy: 0.8254\n",
      "Epoch 5/20\n",
      "13332/13332 [==============================] - 2s 172us/sample - loss: 0.4446 - accuracy: 0.8564 - val_loss: 0.4432 - val_accuracy: 0.8479\n",
      "Epoch 6/20\n",
      "13332/13332 [==============================] - 2s 172us/sample - loss: 0.4004 - accuracy: 0.8706 - val_loss: 0.4098 - val_accuracy: 0.8566\n",
      "Epoch 7/20\n",
      "13332/13332 [==============================] - 2s 178us/sample - loss: 0.3654 - accuracy: 0.8811 - val_loss: 0.3832 - val_accuracy: 0.8626\n",
      "Epoch 8/20\n",
      "13332/13332 [==============================] - 2s 172us/sample - loss: 0.3376 - accuracy: 0.8898 - val_loss: 0.3617 - val_accuracy: 0.8695\n",
      "Epoch 9/20\n",
      "13332/13332 [==============================] - 2s 172us/sample - loss: 0.3146 - accuracy: 0.8975 - val_loss: 0.3456 - val_accuracy: 0.8728\n",
      "Epoch 10/20\n",
      "13332/13332 [==============================] - 2s 172us/sample - loss: 0.2949 - accuracy: 0.9037 - val_loss: 0.3334 - val_accuracy: 0.8779\n",
      "Epoch 11/20\n",
      "13332/13332 [==============================] - 2s 171us/sample - loss: 0.2780 - accuracy: 0.9080 - val_loss: 0.3230 - val_accuracy: 0.8758\n",
      "8334/8334 [==============================] - 1s 71us/sample - loss: 0.3106 - accuracy: 0.8841\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=16, batch_size=32, total=  27.0s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=16, batch_size=32 ........\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_35 (Embedding)     (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_35  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 3s 231us/sample - loss: 0.6827 - accuracy: 0.6279 - val_loss: 0.6661 - val_accuracy: 0.6818\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 2s 185us/sample - loss: 0.6329 - accuracy: 0.7489 - val_loss: 0.6042 - val_accuracy: 0.7819\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 2s 174us/sample - loss: 0.5615 - accuracy: 0.8033 - val_loss: 0.5388 - val_accuracy: 0.8086\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 2s 172us/sample - loss: 0.4946 - accuracy: 0.8337 - val_loss: 0.4826 - val_accuracy: 0.8320\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 2s 171us/sample - loss: 0.4381 - accuracy: 0.8562 - val_loss: 0.4378 - val_accuracy: 0.8497\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 2s 172us/sample - loss: 0.3946 - accuracy: 0.8711 - val_loss: 0.4050 - val_accuracy: 0.8557\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 2s 172us/sample - loss: 0.3595 - accuracy: 0.8821 - val_loss: 0.3786 - val_accuracy: 0.8644\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 2s 172us/sample - loss: 0.3319 - accuracy: 0.8907 - val_loss: 0.3581 - val_accuracy: 0.8686\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 2s 176us/sample - loss: 0.3090 - accuracy: 0.8975 - val_loss: 0.3430 - val_accuracy: 0.8716\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 2s 174us/sample - loss: 0.2903 - accuracy: 0.9026 - val_loss: 0.3312 - val_accuracy: 0.8749\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 2s 172us/sample - loss: 0.2741 - accuracy: 0.9074 - val_loss: 0.3194 - val_accuracy: 0.8800\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 2s 172us/sample - loss: 0.2596 - accuracy: 0.9112 - val_loss: 0.3137 - val_accuracy: 0.8782\n",
      "8333/8333 [==============================] - 1s 71us/sample - loss: 0.3140 - accuracy: 0.8804\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=16, batch_size=32, total=  29.3s\n",
      "[CV] vocabSize=8000, epochs=20, embeddedDim=16, batch_size=32 ........\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_36 (Embedding)     (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_36  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13333 samples, validate on 3334 samples\n",
      "Epoch 1/20\n",
      "13333/13333 [==============================] - 3s 216us/sample - loss: 0.6842 - accuracy: 0.6526 - val_loss: 0.6691 - val_accuracy: 0.6689\n",
      "Epoch 2/20\n",
      "13333/13333 [==============================] - 2s 182us/sample - loss: 0.6380 - accuracy: 0.7460 - val_loss: 0.6057 - val_accuracy: 0.7867\n",
      "Epoch 3/20\n",
      "13333/13333 [==============================] - 2s 180us/sample - loss: 0.5666 - accuracy: 0.8060 - val_loss: 0.5377 - val_accuracy: 0.8188\n",
      "Epoch 4/20\n",
      "13333/13333 [==============================] - 2s 179us/sample - loss: 0.4977 - accuracy: 0.8371 - val_loss: 0.4794 - val_accuracy: 0.8428\n",
      "Epoch 5/20\n",
      "13333/13333 [==============================] - 2s 171us/sample - loss: 0.4400 - accuracy: 0.8615 - val_loss: 0.4361 - val_accuracy: 0.8602\n",
      "Epoch 6/20\n",
      "13333/13333 [==============================] - 2s 171us/sample - loss: 0.3957 - accuracy: 0.8738 - val_loss: 0.4008 - val_accuracy: 0.8653\n",
      "Epoch 7/20\n",
      "13333/13333 [==============================] - 2s 172us/sample - loss: 0.3600 - accuracy: 0.8818 - val_loss: 0.3737 - val_accuracy: 0.8713\n",
      "Epoch 8/20\n",
      "13333/13333 [==============================] - 2s 172us/sample - loss: 0.3321 - accuracy: 0.8909 - val_loss: 0.3533 - val_accuracy: 0.8764\n",
      "Epoch 9/20\n",
      "13333/13333 [==============================] - 2s 171us/sample - loss: 0.3093 - accuracy: 0.8990 - val_loss: 0.3391 - val_accuracy: 0.8767\n",
      "Epoch 10/20\n",
      "13333/13333 [==============================] - 2s 171us/sample - loss: 0.2900 - accuracy: 0.9030 - val_loss: 0.3269 - val_accuracy: 0.8806\n",
      "Epoch 11/20\n",
      "13333/13333 [==============================] - 2s 180us/sample - loss: 0.2737 - accuracy: 0.9086 - val_loss: 0.3155 - val_accuracy: 0.8845\n",
      "Epoch 12/20\n",
      "13333/13333 [==============================] - 2s 171us/sample - loss: 0.2599 - accuracy: 0.9135 - val_loss: 0.3103 - val_accuracy: 0.8848\n",
      "Epoch 13/20\n",
      "13333/13333 [==============================] - 2s 170us/sample - loss: 0.2468 - accuracy: 0.9188 - val_loss: 0.2999 - val_accuracy: 0.8878\n",
      "Epoch 14/20\n",
      "13333/13333 [==============================] - 2s 170us/sample - loss: 0.2351 - accuracy: 0.9241 - val_loss: 0.2954 - val_accuracy: 0.8899\n",
      "Epoch 15/20\n",
      "13333/13333 [==============================] - 2s 170us/sample - loss: 0.2247 - accuracy: 0.9257 - val_loss: 0.2906 - val_accuracy: 0.8884\n",
      "8333/8333 [==============================] - 1s 69us/sample - loss: 0.3045 - accuracy: 0.8786\n",
      "[CV]  vocabSize=8000, epochs=20, embeddedDim=16, batch_size=32, total=  36.0s\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_37 (Embedding)     (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_37  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 128,017\n",
      "Trainable params: 128,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 11.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 4s 196us/sample - loss: 0.6750 - accuracy: 0.6586 - val_loss: 0.6409 - val_accuracy: 0.7544\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 3s 170us/sample - loss: 0.5838 - accuracy: 0.7919 - val_loss: 0.5412 - val_accuracy: 0.8032\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 3s 166us/sample - loss: 0.4850 - accuracy: 0.8365 - val_loss: 0.4642 - val_accuracy: 0.8352\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 3s 166us/sample - loss: 0.4122 - accuracy: 0.8632 - val_loss: 0.4071 - val_accuracy: 0.8554\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 3s 166us/sample - loss: 0.3620 - accuracy: 0.8760 - val_loss: 0.3718 - val_accuracy: 0.8646\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 3s 173us/sample - loss: 0.3266 - accuracy: 0.8873 - val_loss: 0.3464 - val_accuracy: 0.8706\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 3s 166us/sample - loss: 0.3001 - accuracy: 0.8945 - val_loss: 0.3282 - val_accuracy: 0.8748\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 3s 167us/sample - loss: 0.2795 - accuracy: 0.9030 - val_loss: 0.3152 - val_accuracy: 0.8808\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 3s 166us/sample - loss: 0.2625 - accuracy: 0.9069 - val_loss: 0.3053 - val_accuracy: 0.8840\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 3s 167us/sample - loss: 0.2479 - accuracy: 0.9122 - val_loss: 0.2978 - val_accuracy: 0.8856\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 3s 170us/sample - loss: 0.2357 - accuracy: 0.9164 - val_loss: 0.2940 - val_accuracy: 0.8840\n"
     ]
    }
   ],
   "source": [
    "#Grid search preprocessing in outer loop.  Random search model hyperparameters in \"inner loop.\"\n",
    "#Log the best model for each preprocessing grid.\n",
    "\n",
    "preproc_grid = {'vocabSize': [8000], 'SEQ_LEN': [256, 512]}\n",
    "pregrid = ParameterGrid(preproc_grid)\n",
    "\n",
    "results = []\n",
    "\n",
    "for p in pregrid:\n",
    "    #Insert p parameters into text transformer \"text_to_integer_seqs\"\n",
    "    vocabul_size = p['vocabSize']\n",
    "    train_seqs, test_seqs = text_to_integer_seqs(train=train_df, test=test_df, **p)    \n",
    "    \n",
    "    #Hyperparameter search within pregrid loop.\n",
    "    hyp_grid = {\n",
    "    \"vocabSize\": [vocabul_size],\n",
    "    \"embeddedDim\": [4,8,16],\n",
    "    \"batch_size\": [16,32],\n",
    "    \"epochs\": [20],    \n",
    "    }\n",
    "\n",
    "    #Callbacks - early stop and save best model\n",
    "    early_stop_cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max')\n",
    "    checkpoint_cb_hpsearch = keras.callbacks.ModelCheckpoint(\"hyp_model.h5\", save_best_only=True)\n",
    "\n",
    "    #Use model like a Scikit-Learn object\n",
    "    class_model = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "\n",
    "    hyp_model = RandomizedSearchCV(class_model, hyp_grid, n_iter=10, cv=3, verbose=2)\n",
    "\n",
    "    hyp_model.fit(train_seqs, train_df['sentim'].values, validation_split=0.2, \n",
    "              callbacks=[early_stop_cb, checkpoint_cb_hpsearch])\n",
    "    \n",
    "    #Log pregrid, hyperparameters, and best score with standard deviation.\n",
    "    results.append([p, hyp_model.best_params_, hyp_model.best_score_, \n",
    "                   hyp_model.cv_results_['std_test_score'][hyp_model.best_index_]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 16, 'batch_size': 32}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_model.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preproc</th>\n",
       "      <th>best_hyp</th>\n",
       "      <th>best_score</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'SEQ_LEN': 256, 'vocabSize': 8000}</td>\n",
       "      <td>{'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 16, 'batch_size': 16}</td>\n",
       "      <td>0.88108</td>\n",
       "      <td>0.006400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'SEQ_LEN': 512, 'vocabSize': 8000}</td>\n",
       "      <td>{'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 16, 'batch_size': 32}</td>\n",
       "      <td>0.88100</td>\n",
       "      <td>0.002305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               preproc  \\\n",
       "0  {'SEQ_LEN': 256, 'vocabSize': 8000}   \n",
       "1  {'SEQ_LEN': 512, 'vocabSize': 8000}   \n",
       "\n",
       "                                                                 best_hyp  \\\n",
       "0  {'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 16, 'batch_size': 16}   \n",
       "1  {'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 16, 'batch_size': 32}   \n",
       "\n",
       "   best_score  std_score  \n",
       "0     0.88108   0.006400  \n",
       "1     0.88100   0.002305  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=['preproc','best_hyp','best_score','std_score']).sort_values(by=['best_score','std_score'], ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In results_df above, we see the hyp_model best scores are about the same for 256 and 512 features.  But, the standard deviation of scores across three folds is much lower with more (512) features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_vocabSize</th>\n",
       "      <th>param_epochs</th>\n",
       "      <th>param_embeddedDim</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.770239</td>\n",
       "      <td>4.948184</td>\n",
       "      <td>1.086663</td>\n",
       "      <td>0.026641</td>\n",
       "      <td>8000</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>{'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 4, 'batch_size': 16}</td>\n",
       "      <td>0.889249</td>\n",
       "      <td>0.878675</td>\n",
       "      <td>0.875075</td>\n",
       "      <td>0.88100</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.800542</td>\n",
       "      <td>19.171604</td>\n",
       "      <td>1.113650</td>\n",
       "      <td>0.038522</td>\n",
       "      <td>8000</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>{'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 8, 'batch_size': 16}</td>\n",
       "      <td>0.730742</td>\n",
       "      <td>0.882035</td>\n",
       "      <td>0.878675</td>\n",
       "      <td>0.83048</td>\n",
       "      <td>0.070543</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.643747</td>\n",
       "      <td>17.277465</td>\n",
       "      <td>1.173160</td>\n",
       "      <td>0.051229</td>\n",
       "      <td>8000</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>{'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 16, 'batch_size': 16}</td>\n",
       "      <td>0.766019</td>\n",
       "      <td>0.883715</td>\n",
       "      <td>0.880955</td>\n",
       "      <td>0.84356</td>\n",
       "      <td>0.054845</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.087873</td>\n",
       "      <td>5.843045</td>\n",
       "      <td>0.579464</td>\n",
       "      <td>0.010247</td>\n",
       "      <td>8000</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>{'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 4, 'batch_size': 32}</td>\n",
       "      <td>0.882289</td>\n",
       "      <td>0.867395</td>\n",
       "      <td>0.873275</td>\n",
       "      <td>0.87432</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.411162</td>\n",
       "      <td>5.202384</td>\n",
       "      <td>0.599832</td>\n",
       "      <td>0.022554</td>\n",
       "      <td>8000</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>{'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 8, 'batch_size': 32}</td>\n",
       "      <td>0.873290</td>\n",
       "      <td>0.875795</td>\n",
       "      <td>0.875915</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.165508</td>\n",
       "      <td>3.851781</td>\n",
       "      <td>0.611267</td>\n",
       "      <td>0.007295</td>\n",
       "      <td>8000</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>{'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 16, 'batch_size': 32}</td>\n",
       "      <td>0.884089</td>\n",
       "      <td>0.880355</td>\n",
       "      <td>0.878555</td>\n",
       "      <td>0.88100</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      57.770239      4.948184         1.086663        0.026641   \n",
       "1      35.800542     19.171604         1.113650        0.038522   \n",
       "2      32.643747     17.277465         1.173160        0.051229   \n",
       "3      38.087873      5.843045         0.579464        0.010247   \n",
       "4      31.411162      5.202384         0.599832        0.022554   \n",
       "5      30.165508      3.851781         0.611267        0.007295   \n",
       "\n",
       "  param_vocabSize param_epochs param_embeddedDim param_batch_size  \\\n",
       "0            8000           20                 4               16   \n",
       "1            8000           20                 8               16   \n",
       "2            8000           20                16               16   \n",
       "3            8000           20                 4               32   \n",
       "4            8000           20                 8               32   \n",
       "5            8000           20                16               32   \n",
       "\n",
       "                                                                   params  \\\n",
       "0   {'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 4, 'batch_size': 16}   \n",
       "1   {'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 8, 'batch_size': 16}   \n",
       "2  {'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 16, 'batch_size': 16}   \n",
       "3   {'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 4, 'batch_size': 32}   \n",
       "4   {'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 8, 'batch_size': 32}   \n",
       "5  {'vocabSize': 8000, 'epochs': 20, 'embeddedDim': 16, 'batch_size': 32}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0           0.889249           0.878675           0.875075          0.88100   \n",
       "1           0.730742           0.882035           0.878675          0.83048   \n",
       "2           0.766019           0.883715           0.880955          0.84356   \n",
       "3           0.882289           0.867395           0.873275          0.87432   \n",
       "4           0.873290           0.875795           0.875915          0.87500   \n",
       "5           0.884089           0.880355           0.878555          0.88100   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.006015                2  \n",
       "1        0.070543                6  \n",
       "2        0.054845                5  \n",
       "3        0.006126                4  \n",
       "4        0.001210                3  \n",
       "5        0.002305                1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(hyp_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn accuracy: 0.883\n",
      "precision - avoid false positives: 0.9\n",
      "recall - find all positives: 0.863\n"
     ]
    }
   ],
   "source": [
    "#Get prediction in probability format.  Convert to binary.\n",
    "test_preds = hyp_model.predict(test_seqs)\n",
    "test_pred_ints = [int(i>0.5) for i in test_preds]\n",
    "\n",
    "#Calc sklearn metrics on test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# precision = tp / (tp + fp)\n",
    "# recall = tp / (tp + fn)\n",
    "print('sklearn accuracy:', round(accuracy_score(test_df['sentim'].values, test_pred_ints),3))\n",
    "print('precision - avoid false positives:', round(precision_score(test_df['sentim'].values, test_pred_ints),3))\n",
    "print('recall - find all positives:', round(recall_score(test_df['sentim'].values, test_pred_ints),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAGjCAYAAABzFsfMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd5gV1fnA8e+hdxALvYogFkRBUQEFsXeNLfaaaGI0mvxM08QSYyxJ7BorxtiNDRsWsFNEbFjAQm9K7/38/pi7sOVuY++yy73fz/PcZ3dnzsycOzv3vvOeOXMmxBiRJEmSJGWvGlVdAUmSJElS5TLxkyRJkqQsZ+InSZIkSVnOxE+SJEmSspyJnyRJkiRlORM/SZIkScpyJn6bkRDCRSGEL0MIy0MIMYTw602wzUkhhEmVvZ1ckPqfvVXV9VDx0v2PQghXpqYPqJpaFeRnUtq8GLs3b9kUu0MIg1Pvp2NV10VVw8QvjRDC9iGE20II40IIC0MIq0IIM0IIL4UQzgkh1KuCOp0E3AKsAG4GrgJGbup6VAepgBZTr4EllHswX7krK7jNAZlYT3WTL6mJIYRfFFPmzNT8v27q+klSWRm7qzdjd+aFEOqkju2XQggzQwgrQwiLQwifhBBuDiH0qOo6Zkq2vNeqbpSpVVUbrq5CCH8G/kKSFI8EHgKWAC2AAcB9wAVA701ctcPzfsYYZ2zC7Q7ahNsqrzXAecDwwjNCCE2AE1Jlqstx3h1YVtWVKMGVIYT/xhgXVXVFqpnbgceBKVVdEUnpGbuLMHZnTrWM3SGErsBzJPWbA7xOEqfqADsA5wMXhRCOjjG+UGUVzYBceq+Vrbp8qKqFEMIfSVrjpgLHxxhHpSlzOPCbTV03oDXAJg4cxBi/25TbK6cXgWNDCFvGGOcWmncK0AB4Fjhmk9csjRjj11VdhxJ8C3QBfgf8qYrrUq3EGOeQBBpJ1ZCxuyhjd+ZUx9gdQmgBvAm0JbmS/McY4/JCZbYhaQzZYtPXMHNy6b1uEjFGXzECdARWpV47lVK2bpppJwDvAAuB5cDnwB+KKTsp9WoA3EjSarGS5OT7d0DIV/ZKIKZ75at3BAYXU9e38srmmxaAM4APgB9JuqBMBYYCJ6ara7p9APwe+IykJWwR8C5wQjH7NgKDU78/TnIivQIYQ9ISWp7/1aTU+g5N/fx1mjJjU/v1Z6kyVxaa3xX4e2r7P6b2/2TgHqBtobKDi/sfAANSZc5M/X0mcHBqvy/Mv+9T89/K93cnYAEwD+hQaJsNga+AtcC+lXjc5x1fFwHTU//Lwu8/7739Nc3yrYA7Uv+TVal9+QzQK03ZMu8jklb6B4DZwNLUsdo/3765MfX/Wgl8QXKyV3h7TYH/A4YB0/LV7wVgz2L2R4H/UaF9NKDw56qEV+F11AJ+QXIlYlFqP38MXAjUSFOPkJr3BcnnZDrJlcemFPOZ9OUrF18Yu43duRm7703V69EylK2b7/e8fdKxUJkzgf8B35N8DhYB7wOnFrPOzql9/m2q/DySz87dwJb5ytUhOb8YC8xPHXOTgOeB/Svzvab+Ls85ypUUivXpPgvFHGMdgZ+n9sEKknOXe4Cm+coOKOF4HJyvXH9gCMl5y0pgFsm5w18ycex4xW+Ds4DawOMxxnElFYwxrsz/dwjhbySBYg7wKEn3kkOAvwEHhRAOiDGuLrSa2sBrJK2Br5B0azia5AutHknrJSRfQpB8KDvkm14R16bqOxF4kuRLrhWwO3A88ERJC4cQ6pAEmn2Br0k+VA2A44AnQgg9Y4x/TLNoB2A0yRfLw0Bz4ETg+RDC/jHG4eV8H6+TfJjPJWkFyqtfL2BXkn21rphljyXpGjCcJIiuAnZMreuIEELvGOP0VNnnUj/PAN5mw/+E1PbzO44keLxC8gXYsbjKxxgnhhDOBZ4CHgsh7BNjXJOafSewPUnQe7u4dWTQMuAK4H6S4+OM0hYIIXQC3iM5hocBjwHtSI6hw0IIP4kxvphm0dL2UTOSgLM4tc7mwEnA0BDCXsC/U9NeJPkc/ZTkuJsaY8x/70z31Ht5B3iJJOi0B44EDgkhHBFjfLW091mMwRQ8DvL0B/YjX7egEEJtki/xg4DxJN8RK4CBwG1AH+C0Quu5mSRYziQJHquBo1Jl65Acr5KM3cbuHIvdIYT6bIgZpR5XhY/7YtwFfEkSL2cCW5Ik6A+HELrFGK/It/1WwIdAE+BlkoSxHklCfBpJI2XeldzBJDF6HPAfkiSxNdCPZH+/UVKlKvJeK3COsjFuIInxQ0i+HwaSdGfuQnJOAMkxdxWQN7jTzfmW/yRV54NJzlcWkTRSTyf5vHUnaTyu+PdIZbVGbG4vksvIETi3nMvtlVpuCtAy3/RaqQMgklyWzr/MpNT0l4H6+aZvQ9KKtACoXWiZtyjU+hdLaIUoaTmSD+Q0oEGa8lulqeukQtP+kK/+tQrVP++97Z2mjpFCLRYkH5QIvFyOfZ63jVrA5anf98o3/26S1rb2JMEgXathG9K36B6YWvauQtMHpFtPvvlnpuavAw4upkyRK0Gp6Xem5l2X+vv01N/DSXM1KMPH/ZV5xz3JvTGfpt5/zzTv7a+Flh2amv6nQtP3JjkZmgs02oh9FFP/wxr5pp+Wmj6P5HNVL9+8/ql5zxZaV9PCx3NqeltgBvBVWf5HlNAKWKhcD5Iv6x+BLmmWvw2omW96TZJEOwJHFdp/kaQltXm+6fWAEal5k0qqiy9fufLC2J03z9idI7GbDTFv2kYsO5j0V/y2TVO2TurztRpok2/6r1LruDjNMg3zPhskMXgdydXZmmnKblmG+lbkvZb3HOVKNv6K3xSgfb7ptUiS6AjskeZzMKmYOv8vtcwuaeYVOZ/ZmJejem7QKvVzWjmXOzv1868xxll5E2PS+vMbkoP+3GKWvSjm66ccY/yB5PJ3U6BbOetRXqtJviQLiMn9TKU5m+TAvDRuaOXKq/81qT/TvefJQIGRIWOMQ0k+MHuUrdpFPEDyPs4DCCE0BE4GhsYYix2MI8Y4PaZpBYsxvkbSve6gjazP87H8V5EuJUm4fhdCuJAkmPwInBJjLK7VM+NS27qMJAG8qaSyIYS2JIF2CklLV/71fMCGK3XHplm8tH20DPi/Qu/9UZIv6i1Igs2KfNt7l+SLtGeheixMdzzHGKcBTwPbhxDal1CPMgshtCZppatNksR9m5peg6TL5izgkhjj+s9c6vffkHyWTsm3urNSP6+NMc7LV34FyYmbpA2M3Ri7cyx2b+wxX6yY5p7QGOMqkqvCtUg/WNDywhNijEvzfTYiSffklaS5ghuL3t+Zzka91wqeo2yMq/Mft6nP14OpPzfmM5Ju32ZkrAG7em4QUj9jOZfbLfVzWOEZMcYJIYRpQKcQQrMY44J8sxfmnRwWMjX1szJvUH2EpMXmixDCUyRdIEbEGBeWtmAIoTHJpevpMf0Nz3n7Ydc08z7Jf+Kbz1SS1tdyizHOCCG8DJwQkmcjHQ80JukTXqwQQiA52T4T2IVkf9fMV2Rju9KNLu8CMcYVIYQTSVrFbiM5Bo+LZRwMIITQjA1dB/K7udAxV5a6DA0hvAYcGEI4NMb4cjFF8/6/78aiXaEgOQ5OTZX7T6F5pe2jCTHGxYXqtTaEMBtoGGP8Ps0y00m6QRYQQugLXExyfG1D0oKZXxsqOFpnCKERSbfTNsBPU0ElT1eSLjPfAJcnh10Ry0m6ceTJ+05J103oXZIEWFLC2G3szrXYvbHHfEl1aU9yn+ogkiuu9QsVaZPv9xdIukPfEUI4iOTK2vvAlzF1aQogxrgohDAEOAL4JITwP5IYNirGWNZRUjf2vVbkHGVjjEkzbWO+Ex4hSUZHhRCeILl6/H6qwTojTPw2mEHSL7ttOZdrmvo5s5j5M0k+RE1JuoHkKe5DnXdSV7OY+ZlwCfAdSevf71OvNakv4d8UE9TylOX9QnKfVmElveeKXH2+l+SL5ackV0tmkXTVKck/Sb5wZ5J8aU1nQwvLmST3NGyMWaUXSWsCyc32e5P0s3+tHMs2IxnNqrDBFL/PS/Jbkv7mN4QQhhZTpiLHQWn7qLiTmDWlzCvwfRZCOIbkyt4KkntKviMZKGYdSfeffUkGOthoIYSaJAMe7Ar8IcZY+B6bLVM/tyP9/yhPo3y/5+3b2YULpRLgsrSSSrnC2G3szrXYnZdYlveYTyuE0Jkk8d2CJDF7jSTWriXp4ngG+WJljHFyCGEPkq6RB7PhqtnUEMJNMcZb863+RJKE8mQ23J+2IoTwNPDbGGOROFfIxr7XihzvGyPd/6vc3wkxxmfyjUB8NsmAMYQQPiI5x3i9ohU18dvgPZIbMAeR3HdTVnknoi1JvpALa1WoXKblXT4v7n9Z5KBOtdzdAtySGgK3H8ngGccDO4YQdkzXlSIl//tNp7Lfbzovk3z5X07y5XBd/m4shaXe80UkNxvvXfjqUgjhpxWoy8a2wP2eJHDMIblR/Q8kN/KXvsEYJ7GhVazCYoyfhxAeIgnEZ5N0LSqsIsdBxlopS3ENSetv7xjjV/lnhBD+TZL4VdStwGHAvTHGv6eZn/f+n40xlrVLSd4yLUgGU1gvlWhuSXK8SzJ2G7s3zM+V2D2GpPtk29TAK+M3Yh35XUoSV86KMQ7OPyO1T88ovEAqpp4YQqhFcuV1f5Kr0beEEJbGGO9PlVtOkiBeGUJoB+xDkqCfSpJU9i+lbhv7XjfmeC/pM5mpBLFUMcaXgJdS3Z/7kDwL9ALgxRDCrjHGLyuyfu/x2+BBkhPcn4QQdiipYAgh/1WCj1M/B6Qp14Xky2xiebvclcP81M92abbfhKSrWbFijD/EGJ+JMZ5Acul7W2CnEsovJgmSbUII26UpMjD1c2wZ6p4RqWD4AMm+jpQe/DuTHPuvpQkcbVPzC8vr5pLx1twQwt7A1SQjPu6U+nlVCKFfprdVDpeT3Gt3NcnN2oXlHff9Ul/8hW3y4yCNLiRdTwonfTVITpgqJITwG5JRtl5L/Uzna5KWwD1To3uWRd4+S5eY9scGOyk/Y7exO6didyqZejj15xUllYUix306XVI//5dmXokNpDHGNTHGj2KM15NcuYVklNt0ZafGGB8huQ/zG5Lzhy3Tlc23zMa+1405Ryn2Mwn0Lm3b5bCWMhyPqfslh8UYLyXpWluHZNThCjHxS0m1vFxJsmNfCiGk/Senhlp9Jd+kB1I/Lw8hbJ2vXE2SATJqUL5WyHJJffl9DfTNH/RS2/8nhfpphxDqhhAGhUI3G6VOSpun/iyt7/UDJK1UN6a2k7eOrdjwwXwg3YKV6FaSh70elO4m5UImpX72K1T/RiRdT9J9SeR1r8vIYCD5trkFyU3Ga4GTUt0eTiTpIvBYaV+KlSV1j8I/SFrLityDkOpv/jpJi12B+SGEPiTdOuaTPIS3qkwCtksNvAKsvz/kL0CJJ4ilCSEcS3LD+OckzxBM20qdmn4bSeviramhqQuvq1WhE9bBqZ9/CiE0z1euHnBdReotZRtjt7E7R2P35SQDnpwSQrixmNiyVQjhVpKrwiWZlPo5oNDyB5FmsJ8Qwh4heah6YXnTlqXKbZ06HyisIcn9nGso2z2Z5X6vG3mOknef51n5k8XUlco/l6GeZTUX2LqY9zEo3XQK7duKsOU4nxjj31L/7L8AH4YQPiC5zLyEZKfvQ3Kvzph8y3wQQriBZDTEcal+y0tJsvKdSLqh3FjJVb+RJEC9H5IbvvOeEVabZMSpXfKVrU/y3JRJIYRRJKN11QMOIBlg4oXCV0jSuInk/R0FfJq6v6ABSXeTbYAbYozvZei9lUlqtKPnSi2YlJ0VQnic5Avik5AMZtKUZB+sILm/rWehxcaTdEk5KYSwimRAkAg8HGOcXIGqP0ASkC6KMX6Sqt+nqatJt5O0Zh9ZgfVXxA0kD9HtUsz880lu6L4xhHAgyeci7xk560i6jSwuZtlN4V8kw4N/HJKbylcDfUmSvrwbzjfWf0lODD8ELg1FB22ZlK/LzDUkn8HzSZ4zNYzkWNqG5PukL/AnkvtDiDG+H0K4jaTbTN53St5z/OZT/D0LUk4ydhu7ybHYHWOcHUIYRLLvfgucEUJ4neT91SE5JgaQ3JuX9gpcPneS3NrxVCpWTif5DBxM8rzIEwuVPxn4ZQjhbZLHDs0nueJ8BEm3zLzn07UBRoYQviK5sjaV5Nl/h5M0Kt9alnOECrzXcp2jxBhHhRDeIfm+GJ2K1S1S72so6a8Ebow3SZ69+WpqeyuBT2OMQ0ga3DuGEN5iw0Pne5F0Z59MMqZAxcRKes7I5vwiOYhuI+lHvii142eStBaeQ/pnyJxEEigWk3wBfUFyMlcvTdlJFP8MjytJ8xwRinkWUL7556S2uZLkJuV/k/TZLrAcSUC5LPVepqTq+iMwkuRDUqcsdSUJOH9M7aPlqff9HsmohoXLdqSczysq5f8zKbW+WmUoW9yzgBqQ9MP/NrUPppIMW1xkn+VbZneSD+xCki+N9f8nNjwL6MwS6lLgWUBseBbO88WUfyY1/5JKPNbzjre0z8AiubE47zlOf00zvw3Jg18npz4neUF89zRly72PyvG5Ke5/dibJycDSVN2eBXam+M9Zke2nK5tvnxT3KryOQPIswjdJnkW4iiS4vkfyOWqXpvyFwFckn+kZqeOzaUn7wZevXH5h7C61rhi7syJ259tWndQx9HLqWF+V+p9+TnI1dedC5Qen6tax0PS9SboMz893TBxNmucgktx3dhdJ48S81HH0LUmyu1O+cs1IrpTlNXauTNXxLZJuoaEy32tqmTKfo+Sr873AD6n6jiNpAE/7WShuf6bmFdl3qekNU3WaRnLVc/16gRNIriR/Q9JwtShVh2uBrTNxzITUhiRJkiRJWcp7/CRJkiQpy5n4SZIkSVKWM/GTJEmSpCxn4idJkiRJWc7ET5IkSZKynImfJEmSJGU5Ez9JkiRJynImfpIkSZKU5Uz8JEmSJCnLmfhJkiRJUpYz8ZMkSZKkLGfiJ0mSJElZzsRPkiRJkrKciZ8kSZIkZblaVV2BTAkhxKqugyRtbmKMoarrIKVjXJek8isprmdN4gcwb+maqq6CVEDzhhs+YvX6XVGFNZEKWvHeNVVdBalMjO2qTozrqq7KEtft6ilJkiRJWc7ET5IkSZKynImfJEmSJGU5Ez9JkiRJynImfpIkSZKU5Uz8JEmSJCnLmfhJkiRJUpYz8ZMkSZKkLGfiJ0mSJElZzsRPkiRJkrKciZ8kSZIkZTkTP0mSJEnKciZ+kiRJkpTlTPwkSZIkKcuZ+EmSJElSljPxkyRJkqQsZ+InSZIkSVnOxE+SJEmSspyJnyRJkiRlORM/SZIkScpyJn6SJEmSlOVM/CRJkiQpy5n4SZIkSVKWM/GTJEmSpCxn4idJkiRJWc7ET5IkSZKynImfJEmSJGU5Ez9JkiRJynImfpIkSZKU5Uz8JEmSJCnLmfhJkiRJUpYz8ZMkSZKkLGfiJ0mSJElZzsRPkiRJkrKciZ8kSZIkZTkTP0mSJEnKciZ+kiRJkpTlTPwkSZIkKcuZ+EmSJElSljPxkyRJkqQsZ+InSZIkSVnOxE+SJEmSspyJnyRJkiRlORM/SZIkScpyJn6SJEmSlOVM/CRJkiQpy5n4SZIkSVKWM/GTJEmSpCxn4idJkiRJWc7ET5IkSZKynImfJEmSJGU5Ez9JkiRJynImfpIkSZKU5Uz8JEmSJCnLmfhJkiRJUpYz8ZMkSZKkLGfiJ0mSJElZzsRPkiRJkrKciZ8kSZIkZTkTP0mSJEnKciZ+kiRJkpTlTPwkSZIkKcuZ+EmSJElSljPxkyRJkqQsZ+InSZIkSVnOxE+SJEmSspyJnyRJkiRlORM/SZIkScpyJn6SJEmSlOVM/CRJkiQpy5n4SZIkSVKWq1XVFVD5/DB7FvfcdRsj33+PhQsXsOVWW7PvwEGc8/Nf0KRJ0zKtY9jrQxn70Yd8M+FrvpkwnmVLl3LQoYdz1bU3pC0/e9ZMHnrgXr7+6gtmzZzB4kWLaNq0GW3ateOIo47l4EOPoFbt2gWWOfrQ/Zk1c0aJ9fjZBb/i7J9dULY3rs1Cm62bcMU5+3Fgny40b9KAWXMXM+Tdr7n2weEsWLKizOs5eK+u/PK4PenecWuaN03W8/H4Gdz6xAhGfTG12OVOObgnpx+6Kztt24L6dWsze+4SPvp6Olfe9ybfTp27vlzfXTpw9hG92GW7VrTcsjEN69Vm1twljPt+Nnc8PZK3Pvq+QvtBkjZGeeLz1X/+Iy8Pea7E9fXeow+3//vB9X//MHsWLw15jm/Gf82E8V8xfdo0Yow89fwrtGvfodj1rFixgocfvJfXh77CrJkzaNiwEbv13p1zz7+QTp233fg3rGrnmAE70L9nR3p0acXOXVrQpGE9HnvtU86+5n/FLrPnTu343en7sseObalXpxbfTZ/Hf176mDv/N5J162KBsl8/eQkdWm1RYh2uuu9N/v7Q2wWm9evZkUt+2pc+O7ajUf06TP9xEUPe/YrrHnqbhcWcX2TqnCSbmPhtRqZNncJ5Z57C/Hlz2WfAfnTo2Jkvv/icJx59mJEfvMc9Dz5C02bNSl3Pg/fdzTcTxtOgQQO2btGSyRNLPsmdNm0qQ195kR136sG+AwbRpGlTFi5cwIj33+WvV17Oyy++wK133UetWhsOp5NOOZ3FixcVXVmMPPTAvaxZs4a9+vYv9z5Q9dWp9RYMv+s8WjRvxJB3v2L85Dn07t6GC0/YiwP6dGG/X9zHvEXLS13PX88/gN+c0p85C5Yy5L2vmbtgGdu2bc7h/bbn6H134Jxrn+Hx1z4rsEzdOrV45OoTOaxvN8ZP/pEnX/+cxctX0mrLxvTdpQPbtduyQOI3YLfODNitMx9+OY23x05k6YpVtNumKYf1257D+23PdYPf4ur7h2V8H0lSScoTn/cduB+tWrdOO+/Vl4YwfdrUInH2qy/H8e87biWEQOs2bWnUqHH6WJ3PqlWruOiCc/nsk7F032EnTjj5NH6YNYs33xjK++++w+33PMBOO+9S/jeraul3p+/LLtu1YvGylUz/YRFNGtYrsfzh/bbnsWtOZMWqNTw9bBzzFy/n0L27ceNFh7DXzu045c9PFih/+1Mjadqo6DpDgP87tT91atfitZHfFJh31hG9uP23R7Bm7Tqef+crpv2wkJ5dW3PxSX05ZO9u7PeL+5i7cFmBZTJ1TpJtqjzxCyEcB+wL9AR2ARoDj8QYT63SilVDN153DfPnzeXSy/7ICT/dsHtuvul6Hn/kIe6+/WZ+d/mVpa7n17/9PVtv04J27Tsw9qMP+eV5Z5ZYvscuPXn97ZHUqFGwZ/Ca1au56BfnMXbMaN4a9jr7H3jI+nknnXJ62nWN/OA91qxZQ9ftu9N9x51Kras2H7f85ghaNG/EpTe/xF3/G7V++vUXHsxFJ+7Nleftz0X/GFLiOlo0b8SvT+rLrLmL2ePMO/lxwdL18/bZtRNDbz2LP5+zX5HE7++/PIjD+nbjhoff4cp73yTGgi2MtWoWPHZveuRdrn1weJHtt96qMR/cfwGXnbYP9zw3mllzl5T5/UvawNi+ccoTn/cduD/7Dty/yPTFixfx34ceoHbt2hx2xDEF5nXfYSfuvv8/bNd1exo2asQF557Bxx99WGKdHnt4MJ99Mpb99j+Qv17/z/XnAvsfeDCXXforrr3ych556vki5wjaPF1226tM/3Eh302bR/+eHXnttrOLLdu4QV3uuOxI1q6LHHTRg4wdn/T0uuq+Ybx685kcO3Anjh/0JU+9OW79Mrc/NSLtuvbfowt1atfi4wkz1q8HkvOCf1x8KGvXRQb98n7GfDV9/bxLftqXv/3iIK775UH87G/PFlhfJs5JslF1+JReDlxIEhyml1I2Z02fNpVRI96nVes2HHfiyQXmnXfBhdSvX59XXhrC8uXLilnDBr1270P7Dh0JIZRp27Vr10n7hV6rdm32HTgIgKlTJpdpXc/97ykAjvnJCWUqr81Dx1ZbcMAeXZg0Yz53PzO6wLxr7h/GkmUrOfmgXWhQr3Yxa0i0b9mMmjVr8OGX0wokfQDvfDyRRUtXsFWzhgWmd2q9BecdtTtjvpzGX+55o0jSB7Bm7boCf69ctSbt9mfMWcyocVOoWbMGnVo3L7GukkpkbN8I5Y3P6bzy4gusXLGCAfsdQLMtCnap26ZFS3ru1puGjRqVaV0xRp59+gkALvz1bwucC+wzcBA9d+3FxO+/KzV51ObjnY8n8t20eWUqe8yAHdhmi0Y89ebnBZK1lavWcOV9bwJw3tF7lGld5xzRC4D7nx9TYPpBe25H/bq1GfLuVwWSPoCbH/+AH+Yv4cT9d2aLxvXXT8/UOUk2qg6J3yVAV6AJ4A1fxRgzOmmt6LPX3kWSsIYNG9Kj526sWLGccZ99usnqtHbtWj547x0AumzXrdTyc+fO4b13htOgQQMOPOTwyq6eNqEBvToB8MaH3xZJvJYsX8WIcVNpWL8Oe+zYrsT1fDt1LitXraH3Dm3ZsmmDAvP67tKBJg3rMXzMdwWmn7B/D2rWrMF/X/2EJg3rctKBPfjtqf05+4hedG5TvuRt62YN2X2HtqxYuZoJU+aUa1lJBRjbq8jzzz4NwNE/Ob7C65o2dQqzZs2kfYeOtG7Ttsj8vK6keecoyi0DenUG4PVR3xaZ996nk1m6fBV77tSOOrVrlriebbZoyKF9u7F42UqeeL1gj54WWzYGYOKM+UWWizEyZeYC6tSuRb+eG+5RzdQ5STaq8q6eMcb1/a0q0sKV7aZMnghAu/Yd085v174Do0a8z5TJk9m9z16VUocF8+fz1BOPQIzMnz+f0SM/YNrUKRx4yGH022dAqcu/+NwzrFmzhsOOPIaGDRuWWl6bj67ttwIocB9dft9NncsBe3Rhu3ZbljhwyvzFy7n87te5/sKDGPvwhQx592vmLVpG59bNOaxvN94Y/S0X3liwa0av7ZN7XJo0qscXj/+6wBXBdevWcc9zH/KbW14ucoM5wG7dWnPI3t2oVbMGbbZpwmF9u9GkQV0uveXlIvcLSCo7Y2OkFHQAACAASURBVHvV+PzTT/jumwm079CRXrv3qfD6pkyeBEC7Dh3Tzs8bEGbKlEkV3pY2P13bJbH/m6lFG0rXrl3HpJnz2bFzCzq13oLxk4tvTD39sN2oU7sWD7/yCUuWryowb26q90/HNAPChBBo3yoZ26Jb+60ZwtdJvTJ0TpKNqjzxU9ksWZLca9SoUeO08/O6bSwp5SbtiliwYD73//vO9X+HEDjl9LO44MJflxrYY4y88FwyItTRx1a8FVLVS97N3wuXph8lK296uhu6C7v9qRFMnjWfu39/NOcc2Xv99G+nzuW/r3xcpAvoNlskx/6fzx7IsI++5w93DGXyrAX07t6G2397JOcf24c5C5alvadvt+1bc/nZA9f/vWjpCn729+d4bOimu3IuSZny3DPJQBpHHXtcRta3ZMliABoV0zW0YePknGTJ4sUZ2Z42L00a1QVg4dKVaecvSk1v1qh+2vl5zjo86eb5wAtjisx7Y/S3rF6zliP6b89u3VoX6FL6qxP2Wn8O0KzxhvOLTJ6TZBsTv2yRupRdmS2rHTt1ZuTHX7J27Vp+/GE2bw9/k3vuuo1PPx7LP267i6ZNix9RdPSoEUyfNpVu3XdwUJcctP64LHrRrYhLT+7HVecN4s7/jeKu/41i9rwldOuwFVf//AAG/+V4emzXij/d9dr68jVrJOueNXcJJ/7xMVak7t97e+xETr7icUbcfwEXnbgXNzz8DqvXrC2wrfueH8N9z4+hbp1adGzVjPOO2p0HLv8Je+3UPidv+pa0+VqyeDFvvjY07aAulWYTnHto85V3VKS79z7Pfr23pXOb5owdX3BQlzxTZi/k6vuHcc3PD2DYnefy/DtfMv3HRfTo0opBu2/LZ9/OokeXlqxN06un2HqV45wk21SHe/w2WgjhZyGEMSGEok0EWSavtS2v9a2wpUuTqyANi7kimEk1a9akZavWnHjyafz+T1cy7vNPufeu20tc5vn/Ja2QXu3LTovyWs+KGfa5SYO8VsGSn5vTv2dHrr3gQF56fzy/u/1VJs2cz/KVq/lkwkxO/ONjTP9hIRefuHeBLh/zU8/ieW30N+uTvjyffzebSTPn06RhPbbvsFWx2125ag3jJ8/ht7e+wr3Pfch5R+/OMQN2KP2NS8qoXIrrmfbqy0NYsWJ52kFdNlZeL6O8XkeFLU1NL+tgMcoui5YkV/SaNqybdn7jhqXH/nOOLP5qX56b/vsux//hUUaOm8pBe3bl/GP70KxxPU6/8kmGjpwAwI/zN/QGytQ5STbarBO/GOM9McbeMcbepZfevLXvkNyoOrWYfvR5o2q271D8A1grQ96N3WPHjC62zLx5c3nnrWEO6pLF8gZC6dJuy7Tzt01N/6aY/vZ5Dt07GSTo7Y8nFpm3fOVqxnw1nZo1a9Cza6v1079Jbbu4B7guWJxMr1+3bKN3vTYqeX7QPj07lam8pMzJpbieac8/k4yaffRxmRs1u33q3r6pqXv9Clt/7lHM+APKbhNS9/Zt165ow2rNmjXo2GoLVq9Zm3ZgFkgGVDu83/ZpB3Up7MX3vubgix+k5SF/o/n+19DvvH/z1Jvj2HOn9gB89PWGET8zdU6SjTbrxC+X9No9GQ531IgPWLeu4ND0S5cu5bNPxlK3Xj126rFpH6L64w+zgeQqYHFefP5Z1qxZwwEHH+agLlnq7bFJorb/7l2KdPlpVL8Oe+3UjmUrVjH6i6klrqduneQ4KvzIhjx501et3tBlc3jqxuwdOrUoUr5O7Zps2zYZ2XPyrAVleSu03ipp4S78CAhJqq7Gff4p30wYnwzq0rtsw+eXRdt27WnZshVTJk9ixvRpReaPeP9dAHrvUfGBZLT5yRsY5YA+XYrM67dLBxrWr8PIcVMLxOz8Tj90V+rUrsWTb3xeZFCXsujafiv23rk9E2fMY+S4DecXmTonyUYmfpuJtu3a02evvsycMZ2nn3i0wLx777qd5cuXc+hhR1K/fjIE/prVq5k08XumTZ1S4W2P+/xTVixfXmT6smVL+eeN1wGwd/990y4bY+SF1NDSPrsve02cMZ/XR39Lx9ZbcP6xBU86rjhnPxo1qMsjr37KshWrgeSB6l3bb0Wn1gW7I73/adJ6fPYRvdYnYHkO7LMde+3cjuUrVzNy3IbjeujIb/h++jwO2GNb9uu9bYFl/nDGAJo1rs87H09k9rwNXZX69Uz/nKxOrbfgd6cnx/IrIyaUdzdIUpV4PvWM3KMyfDtFCIFjjjsRgNtvvqlAw/M7w9/kk48/olPnbdm11+4Z3a42D8++9SU/LljK8YN2ZrdurddPr1unFleemzzn+d7niu8Rdubhec/uK/k5kI0bFO1KunWzhgz+y3HUrFmDy+96vcB9hOU9J8kloaQbLje1EMIAYDjwSIzx1HIuG+ctTf9Q5mwxbeoUzjvzFObPm8s+A/ajY6fOfDHucz76cBTtO3Tk3sGP0rRZMsDKjBnTOfawA2jZqjXPvfxGgfW8PfwN3h4+DIB5c+cw8oP3aNO2HbvsmnwAmzVrxkWXXra+/GWXXMjYMR+ya6/etGjZinr16/PDrFmMeP9dFi9exM677Motd95DgwZFr9J8OGoEvzr/HLp134GHHn26snZNtdW84Ybxk+r1u6IKa1L5OrXeguF3nUeL5o0Y8u5XfD35R3bv3pYBvTozYcocBl5wL/MWJQ0I7Vs2Y/xTlzJ55ny2P+Ff69cRQmDIP05n0O7bsmjpCl5456vU4C5bc+jeXalRowa/veVl7nh6ZIFt771ze4b883Tq1KrJC+9+xZRZC+nVvQ39e3bkh/lLGPTL+wsM6zzz5T+wcMkKPvxyGtN+WEStmjXo1KY5B/bpQu1aNbnz6ZH85paXN82OqyIr3rsGgBijozKoUm1sbA8hRIBsj+35lTc+Q3Kf3eEH7suaNWsYMvStUu/vu/rPf1z/+8gP3mXe3LkM2O8AGqR65Bx5zE/omdoewKpVq/jlz87i808/pvsOO9F7jz2ZPWsmb74xlNq1anP7PQ+w086btrdRVcr2uH5E/+05on93AFo0b8SBfbbj++nzeP+zpGF27oJl/OHOoQXKP3r1iaxYtYanho1j/qLlHNa3G906bM0zw8dxyp+fTLudAb0688rNZzJ2/Az6nnt3iXW67hcHcUCfLoz6YipzFiyjzdbJ45eaNa7PVfe9yd8fervIMuU5J8kWZYnrjuq5GWnbrj2DH3mSe+66jZEfvMcH773DVlttzQk/PZVzfv6LEkfVzG/C+K95echzBaZNnzaV6dOSS94tW7UuEFiOOvZ46tWvz1dfjGPsRx+yYsUKmjRuQrfuO7D/gQdz+FHHUqtW+kPpubx7DhzUJetNnDGffufdzRXn7McBfbbjoD23Y9bcJdzx1AiuffAt5i8u/Qs2xsjR//cw5x/bh+MH7cSR+3SnQd3azFu8nFdHfsOdT4/kzQ+/K7LcB59Poe95/+ZPZw5gn9060axRPX6Yt5T7nv+Qvz/0NtN/LPiYk78+MJxBe3Rhjx3bcWjfBtSsUYMf5i9hyLtf8eCLY3ljdNGH0UpSZStvfAZ49eUXWb58OQccdGiZBnUpvH6At4a9vv733XrvXiDxq1OnDrfdfT8PP3gvQ195iccfeYiGDRux74D9OO/8C+m0bdFuftp89ejSitMO2bXAtM5tmtO5Teq2iZnzCyR+Q979mgMvepDLTtuHo/fdgXp1avHdtHlcdtsrRRpp8zvniNIHdcnz9scT6dm1FYf3255mjeoxf/EK3h47kdueHLE+IS0sE+ck2ajKr/iFEI4Gjk792RI4CPgeeDc1bU6M8bdlWE/WX/HT5ifbWwa1+fKKnypTJmJ7Ll7xU/VnXFd1tblc8esJnFFoWufUC2AyUGriJ0mSqg1juyRVM1U+uEuM8coYYyjh1bGq6yhJksrO2C5J1U+VJ36SJEmSpMpl4idJkiRJWc7ET5IkSZKynImfJEmSJGU5Ez9JkiRJynImfpIkSZKU5Uz8JEmSJCnLmfhJkiRJUpYz8ZMkSZKkLGfiJ0mSJElZzsRPkiRJkrKciZ8kSZIkZTkTP0mSJEnKciUmfiGE+iGEziGEJmnmdQghPBNCWBBCWBhCeCGE0LXyqipJkirCuC5Juau0K34XAt8AO+SfGEJoDLwNHAU0ARoDhwNvhRC2rIR6SpKkijOuS1KOKi3x6w9MjTGOLDT9AqA9MALoArQAbgNaAhdnupKSJCkjjOuSlKNKS/x2AMakmX4sEIGzY4zfxxh/jDFeDHwPHJLhOkqSpMwwrktSjiot8dsamJh/QgihNrArMD7GOKFQ+WEkLYWSJKn6Ma5LUo4qLfGrC9QsNG1HoDYwOk35H4AGGaiXJEnKPOO6JOWo0hK/WcBOhabtTdIdJF1XkcbAvAzUS5IkZZ5xXZJyVGmJ3/vAfiGEAZAMAw2cl5r3epryOwHTM1Y7SZKUScZ1ScpRpSV+/0r9fC2EMJbkvoAewFsxxvH5C6aeCdQXKDxSmCRJqh6M65KUo0pM/GKMY4AzgeVAT2Abkq4gZ6QpfgZQB3gts1WUJEmZYFyXpNxVq7QCMcb/hhD+R9LdY26M8ftiig4B3gG+ymD9JElSBhnXJSk3lZr4AcQYlwMfllJmUiYqJEmSKpdxXZJyT5kSv+KEEGqRtBgGYFyMcXVGaiVJkjY547okZa8S7/ELIXQKIZwdQuiaZt6hwDTgI5L7A2aEEH5SOdWUJEkVZVyXpNxV2qie5wD3AqvyTwwhdAKeIrkpfCrwNdAceDSEsGMl1FOSJFWccV2SclRpiV8/4PM0/fwvAuqTBI9OMcYdgROB2sCvMl1JSZKUEcZ1ScpRpSV+nYBxaaYfDKwBfhdjjAAxxqeBEcC+Ga2hJEnKFOO6JOWo0hK/rYEp+SeEEBoDXYExMcYFhcqPBdpmrnqSJCmDjOuSlKNKS/wi0LTQtJ4ko32NTVN+IRUcKVSSJFUa47ok5ajSEr9JQN9C0waSBI5RacpvDcyueLUkSVIlmIRxXZJyUmmJ32vAziGEy0MITUIIvYELSO4DeDVN+d4U6kIiSZKqDeO6JOWo0hK/G4AFwFXAfJLWwBbAgzHGH/MXDCF0AHYF3q6EekqSpIozrktSjiox8YsxzgT2AYYDK4DpwD9Ihn0u7AySewFeyXAdJUlSBhjXJSl3lXrDdozxC2D/MpS7Grg6E5WSJEmVw7guSbmptK6e5RJCqBFCOCqT65QkSVXDuC5J2SMjQzSn7gM4FzgLaAXUzMR6JUnSpmdcl6Tss9GJXwihJnAU8DOSLiM1SIaDfiMzVZMkSZuKcV2Sslu5E78QQmeSVsAzSUYCA5gD/Bu4P8Y4OWO1kyRJlcq4Lkm5oUyJXwihFnAMSSvgQJJWwFXAM8BPgOdjjH+urEpKkqTMMa5LUu4pMfELIWwHnEcypPNWQADGAoOBR2OM80II6yq7kpIkqeKM65KUu0q74jeepH//D8C/SB7w+kWl10qSJFUG47ok5aiyPM4hAi8DTxscJEna7BnXJSkHlZb4XQFMJhnO+f0QwpchhMtCCK0qv2qSJCnDjOuSlKNKTPxijNfGGLcFDgGeBbYF/g5MCSG8FEI4YRPUUZIkZYBxXZJyV1m6ehJjHBpjPA5oB/yRpLXwEOAxki4jPUMIvSqtlpIkKWOM65KUe8qU+OWJMf4QY/x7jLELcADwNLAa6A2MDiF8HEL4ZSXUU5IkZZhxXZJyR7kSv/xijG/GGE8E2gKXAROAXYBbM1Q3SZK0iRjXJSm7bXTilyfGOCfGeFOMsTvJQ2AfrXi1JElSVTCuS1J2qnDiV8gJwGEZXqckSaoaxnVJyhKZTvwaAE0zvE5JklQ1jOuSlCUynfhJkiRJkqoZEz9JkiRJynImfpIkSZKU5Uz8JEmSJCnLmfhJkiRJUparVdLMEML35VzfVhWoiyRJqkTGdUnKXSUmfkDHjVhn3IhlJElS5eu4EcsY1yUpC5SW+HXaJLWQJEmbgnFdknJUiYlfjHHypqqIJEmqXMZ1ScpdDu4iSZIkSVmuxMQvhFAjhPBkCOGJEELtEsrVSZV5PPNVlCRJmWBcl6TcVdoVv5+kXs/HGFcXVyjGuAp4Djg+hPCTDNZPkiRljnFdknJUaYnfCcAM4LEyrOtxYDpwckUrJUmSKoVxXZJyVGmJ3+7AsBhjqUM5p8oMA3pnomKSJCnjjOuSlKNKS/xaAtPKsb7pwDYbXx1JklSJjOuSlKNKS/xWAXXLsb66QLH3DEiSpCplXJekHFVa4jcD2KUc69sltYwkSap+jOuSlKNKS/zeB/YNIXQpbUWpMgOAdzNQL0mSlHnGdUnKUaGk+7tDCLsDo4BPgYNijD8UU25rYChJy+CeMcYPK6GuJQohlHqjuiSpoBhjqOo6aNMxrktSdisprpeY+AGEEO4Cfg7MBf5NMsLXNCACbYFBwM+ALYG7Y4y/zEy1y8cAIUnlZ+KXe4zrkpS9Kpr41QLuBM4lCQppiwH3Ar+IMa7dyHpWiAFCksrPxC/3GNclKXtVKPFbXzCEvYDzgb5Aq9TkmcB7wD0xxg8qWM8KCSHEej2rpFFSKtaKT+5Y//vy1Z7DqPqoXzuJCyZ+uWtziOsAxnZVJ8Z1VVdlieu1yrqyGOMIYETFqyVJkqqacV2Scktpo3pKkiRJkjZzJn6SJEmSlOVM/CRJkiQpy5n4SZIkSVKWM/GTJEmSpCxn4idJkiRJWc7ET5IkSZKyXImJXwihfQihSVlXliq/T8WrJUmSMs24Lkm5q7QrfhOBi/NPCCH8PIQwtpjyZwHDM1ExSZKUccZ1ScpRpSV+IfXKryWwS+VUR5IkVSLjuiTlKO/xkyRJkqQsZ+InSZIkSVnOxE+SJEmSspyJnyRJkiRlubIkfrHSayFJkjYV47ok5aBaZShzSQjhrHx/NwMIIXyfpmyzjNRKkiRVFuO6JOWgsiR+zUj/xd+xmPK2JEqSVH0Z1yUpB5WW+HXaJLWQJEmbgnFdknJUiYlfjHHypqqIJEmqXMZ1ScpdjuopSZIkSVmuxCt+IYT2pSy/DlgQY1ySuSpJkqTKYFyXpNxV2j1+kyjDTd0hhEnAg8D1McbVFa+WJEmqBJMwrktSTiot8ZtCyQGiBtCc5Gbxq4CBIYQDY4xrM1Q/SZKUOcZ1ScpRpQ3u0rEsKwkh7ALcAOwPnAfcXeGaSZKkjDKuS1LuysjgLjHGT4EjgKnAyZlYpyRJqhrGdUnKPhkb1TPGuAp4GdgxU+uUJElVw7guSdkl049zmAs0yvA6JUlS1TCuS1KWyHTi1xJYmOF1SpKkqmFcl6QskbHEL4TQFDgS+CRT65QkSVXDuC5J2aXCiV8IYcsQwuHAcGArYHBF1ylJkqqGcV2SslOJj3MIIZTnuT0BeCzG+GjFqiRJkiqDcV2ScldpD3APpcyPJH3/PwUGxxgfykitJElSZTCuS1KOKu0B7pke/EWSJFUR47ok5S4DgCRJkiRluYwmfiGEWiGEX2ZynZIkqWoY1yUpe2Qk8QuJM4AJwK2ZWKckSaoaxnVJyj6lDe5CCGEL4EJgd2A18C5wd4xxRWr+4cANQLfUIs9WTlUlSVJFGdclKTeV9jiHrYDRQAc2jAR2NHBkCOEA4G7g7NS8F4E/xxh90KskSdWQcV2ScldpV/x+D3QkGdb5EZJAcBqwL/AScCAwCrg4xji68qopSZIywLguSTmqtMTvEGAy0CfGuAoghHA78DVwAPA4cEqMMVZqLSVJUiYY1yUpR5U2uEtH4OW84AAQY1xO0v0D4AqDgyRJm42OGNclKSeVlvjVB2anmf5D6uf3ma2OJEmqRMZ1ScpRFXqcg62CkiRlD+O6JGWvUh/nAPQMIZxeeBpACOE0NowKtl6M8T8ZqJskSco847ok5aCyJH5HpV6FBWBwMcsYICRJqp6M65KUg0pL/P4D2O1DkqTsYFyXpBxVYuIXYzxzE9VDkiRVMuO6JOWuEgd3CSGcHkLosakqI0mSKo9xXZJyV2mjeg4Gjt4E9ZAkSZVvMMZ1ScpJFXqcgyRJkiSp+jPxkyRJkqQsZ+InSZIkSVmuLM/xaxZCaF+elcYYp2xkfSRJUuUyrktSDipL4ndx6lVWsYzrlSRJm55xXZJyUFm+yBcBCyq7IpIkaZMwrktSDipL4vevGOPVlV4TSZK0KRjXJSkHObiLJEmSJGU5Ez9JkiRJynImfpIkSZKU5Uz8JEmSJCnLlTi4S4zRxFCSpCxhXJek3GUAkCRJkqQsZ+InSZIkSVnOxE+SJEmSspyJnyRJkiRlORM/SZIkScpyJn6SJEmSlOVM/CRJkiQpy5n4SZIkSVKWM/GTJEmSpCxXq6oroPJps00zrrjgMA7suwPNmzZg1pxFDBn+Gdf++2UWLF5e5vWcftSenHNsX7pv24qaNWowYfJsHn5hJHc/8Q7r1sW0y+y5Syd+d+7B7LFzR+rVqc13U3/kP8+P4M7H3y52mTx1atfig0cvY8curZk+ez5dDr6iXO9bm4fZs2Zxx+238MF777JgwQK23nobBu43iPN/cSFNmjattPUsW7qUB+6/lzdeH8r0adOoW7cu3XfYkdPPPJv+++xb7HaWLV3Kw/8ZzBuvDWXq1KmEAC1btWbXXXfjD5f/mdq1a2/UfpCk4hyzf0/699qOHl3bsHPXNjRpVJ/HXhrN2Zf/p0jZWrVq8PPj96FHt7bssn1bunduSZ3atbjg6kcY/OyItOvfa5fOHD5gZ/bdvSvtWzenScN6zPxxIcNHT+CmB1/j+6lz0i7Xr1cXLjl9f/r06ESjBnWYPnsBQ976jOvueZWFSwqeX5x6RB/uvfq0Et/n2rXraNT7ojLuFVV3rw99lTFjPmT8118xYfzXLF26lEMPP4Lrrr+pSNnJkyfx5uuv8cH77zFlymTmzplLk6ZN6NFjF0457Qz26LNnsdt54blnefyxR/j+u++oWbMG23ffgdPPPJt9BwwsUvbZZ57m7eHD+Pabb5g3by5r162jVatW7LprL84462w6duqc0X2QDUKMJZ+wby5CCLFez19WdTUqVae2WzF88KW02LIJQ4Z/yvhJs+m9YwcG7NGN8RNnsd9Z/2LewqWlrue+a07jlMP7MHvuIl5+ZxzLlq9kYJ/t2WHbVjz7xsec/H/3F1nm8AE789iN57Ji1Rqefu0j5i9cxqH77ES3Ti155vWxnHLZAyVu8++XHsPZx/alccN6OZX4rfjkjvW/L1+dHZ+14kydMoXTTz2JeXPnMnC/QXTs1Jlxn3/Gh6NH0bFTJx7672M0a7ZFxtezaNEizjr9FL79ZgLbdtmOPnvuyfLly3lr+DDmz5vHZX/4E6ecenqR7UyfPo3zzz2bKVMms1uv3uzcowcxwozp0xk9aiRD3xhOg4YNM7qPqpP6tQMAMcZQxVWR0gohRIBsi+0jH/89u3Rry+KlK5g+ewHbd25ZbOLXtFF9Zr17IwCz5ixi9eo1tGvVvMTEb+Lrf2PrLRox8tPv+firqaxZu44+PTqyV89tWbJsJYdfcDujPptYYJmzjtmb2y8/iTVr1/H8sE+ZNms+Pbdvx8A+3ZgwaTb7nfVP5i7YcH7Ro2sbjhi4S9rt9911Wwb26cbL74zjJxffvbG7qdrKpbie3wnHHsX48V/ToEEDWrRsycTvvy828bvst5cw9JWX6bxtF3bdrRdNmzZl0qSJvD18GGvXri02Lv/jxuv5z+AHaNGyJQcccBCrV6/m1VdeZuHCBfz+j1fw01NOLVD+3LNOZ86cH+nefQe23GpratQIfPftt4z44H1q1KjBzbfdQb/+xTf+ZpuyxPVqc8UvhNAWuBo4GNgSmAk8B1wVY5xflXWrLm75w4m02LIJl17/FHc9/vb66df/5lguOnU/rrzwCC669vES13HEgB6ccngfJk6bQ//Tblz/RV6rVg0euf4cjtl/V049og//HTJq/TKNG9bjjitOZu26dRx03i2M/XIKAFfd+SKv3nMRxx6wG8cf9ClPDf0o7Tb799qOX50ykIuve5Lb/nRSRXeDqqlrr7mKeXPn8rs/Xs7Jp2xoCb7x+uv4738Gc9st/+KKv1yd8fXcfcdtfPvNBAbtfyA3/ONf1KqVfK3NmzePU046jn/eeAP9+u9Dhw4d1y+zevVqLrnoQmbMmMEtt93JgP0GFajD2rVrqVHDnvBSRRjX07vspv8x/YcFfDflR/r32o7X7ru42LLLVqziqAvv5LPx05g1ZxF/+vmhXH7+oSWu//ZHhvHoSx8y88eFBab/39kHcvWvjuT2y3/K7if8bf30Fls25h+XHcfatZFBZ/2LMV9MXj/vktMH8bdLjuG6S47hZ3/57/rpn02YzmcTpqfd/lsP/QaAB555v8R6avPy29/9gRYtW9K+fQfGfDiac88qmrjl6du3P2edcx7du+9QYPqYD0fz83PP5l833cCBBx3M1ltvs37eJx+P5T+DH6Bdu/Y8+sTT63v3nHH2Ofz0+J/wz5uuZ58BA2jTpu36Ze64+17q1q1bZPsjPnif8887m3/ccH1OJX5lUS3ObEII2wIfAWcBo4F/Ad8DFwMjQghbVmH1qoWObbbkgL27M2n6HO5+4p0C86656yWWLFvJyYftToN6dUpcz1GDkha6Wx4eVqD1bs2adVx154sAXHBSwQ/JMfv3ZJvmjXlq6Nj1SR/AylVruPKOZJnzju+XdnuNG9bj3qtPZfjoCdz39HtlfLfa3EybOpURH7xH6zZtOOmnpxSY94sLf0X9+g14ccgLLFu2LOPrefON15P5v7pofdIH0Lx5c04/42zWrFnNU08UbBB5ccjzjP/6K0457bQiSR9AzZo1CcELYdLGMq4X750x3/DdlB/LVHb1mrW89v6XzJqzqMzr/8fgN4okfcn011m2fBU7bdea5k039GY4qN+OsDof7gAAHtdJREFU1K9XhyFvfVog6QO4+eFh/DBvMSce0pstmjQodds7bNuKPj06MX32fF55d1yZ66zqb48+e9KhQ8cyxcajjjm2SNIH0Hv3Pei9xx6sXr2aTz/+uMC8p55M4vS5Pz+/wC0dbdq05cSfnsyqVat4/tlnCiyTLukD2GvvvjRu0oQpU6aknZ/LqkXiB9wJbANcFGM8Osb4+xjjfiSBohtwbZXWrhoYsEdXAN4Y8TWFu+cuWbaSEZ98T8P6ddmjR8cS19NiyyYATJxetI9/3rTddmhP00b1N2x792Tbr3/wZZFl3hv7LUuXr2TPHp2pU7voBeR/XHYczRo34IKrHimxXtq8jR41EoC99u5X5EpZw4aN6LnrbqxYvpzPP/s04+uZMyc5btu2bVdkfW3bJdNGjyzYJeqVl5IGiyOPPpbp06fx5OOPcv+9/+alF19gwYKcvRAhZZJxvZqJEdasXQsk99/lWX9eMG1ummUiU2bMpU7tWvTbrUup2zj3uKQRePBzI0q991+5qXaqgbZmrZoFpufF/779+hdZpl//fQqUKc3Yj8aweNEituvatSJVzUpVnviFEDoDBwKTgDsKzf4LsBQ4LYSQvTfblEHXDi0A+HbKD2nnf5eavl2HbdLOz5N3la9j66KNrZ3abLX+926dWmzYdsfk928mF9322rXrmDR9LrVr16RT24LrPHJgj/9v777jrKjuxo9/jvSVamhSF1CxRKyogFEQERQ11sReHo0/jUbjY080tmj8qdEYS5SoYI8Ra4wiKKAUe8OCglIEVFQE6W05zx9zd9lytwHLLrOf9+t1X8OdOXPumcvd+73fmXPOcOKhe3HJLU8x61t/TKfZjBnTAOicm5t1e6fOnQGYOWN61u3rU0+LFs0BmDN7donys2fNAmD69GlF1n/y8Uc0aNCACeNe49CDBnLdtVfz97/dwh8uuYhB++/H008NL7OdkkpnXK+ZjhywC00bN+LNSdOLTNZS8LugfcnfBSEEOmV+LxT+XZBNwwb1OOagnuTlrWHY0xM3YMuVFl9/PYc333idho0asdtuPQvWL126lO/mziUnJ6dI9898BbF/5oys9Y56aQT/uPN2bv3rTfz+3LM547RTaNasOZf9sXbMJ1EZ1Z74AftlliNjjGsKb4gxLgImADlA6VMA1QJNM1fgis+sle+nxcsBaNak7K4YL76WdL0494T9inTbqFNnM644a3DB8+aFtpX32gsz65sXeu3WWzTh9suPZcT4T3jgmewD0JUeixctBqBJ4yZZtzdpkqxftGjRBq9nn32Tmb7uvut28jJnswEWLJjPQw8OBWDlypUsX7684N+LFy9m9erV3HLzjZxw4smMGDWG1ya8ydV/vp4Q4Oo/Xc6bb/i5ldaRcb2G6dzuZ/z1kqNZtSqPS28p2l3u5dc/ZdWqPA7p14Ndt+9UZNvvju9H6y2S793m5fy+OPKAXWnRNIeXJnzK7LkLNuwBaJO3cuVKLrv4QlauXMlZxWboXrw4iemNm2SP/Y0zvwkWLcze5XnUqJe4+647GHb/vYx55WW2bNeefwy5l5123mUDH8WmryZM7tI9s5xSyvapJGcOtwFe2Sgt2gQVdLkuZ5bWf7/0LscM7smgvXfgvScv57+vfsSy5Svpt2d3unZoydSZ37F159ZFuoGU/9oFswgVrLvzT8dRr24dzr7m0Uofi9Jn7Wdj/cbNZavnt+ecy+sTJzDypRFMmzaNPffci+XLlzNmzCtsnrM5DRs1YvmyZdTJdB3NK+jqlMf+AwZy/oUXF9R12OFHsnTpUv7/9X9m6H33sudevdarvVItZVyvQVq1aMyzd5xF6y2acN71j/PGh0V7Xnz1zXyuufu/XPu7Qxk99HyeHf0hc+YuoEf3DvTfa1smTZlNj206kLem7N8Fpx3RG4D7nnQ8v4rKy8vjj5dexAfvv8fAAw/i5FNPW6d6ShtfeOPNt3LjzbeyePFivpg6hbvvupOTTziWK668hl8efsT6ND11asIVv/yUv+RI5KLrmxffEEI4I4TwTgjhnSppWQ2Sf1Wt8Ni7wppu3hAo/apcvhgjR/3+Hi695SnmzlvIcYN7ctIv92LO3AX0/5+1t4P4/se1V1TKe+0mxV77uIP34OB9d+TCm4bzdZYB5kqfxk0aA7BocfYreosXZ67kZcptyHpatmrFI48P57gTTmTZsqU8/q/HGDPmFfbZty/33DeUFcuX06RJE+rVTyY+atSoUcH9+fbbf/8Sr9G//wAAPv54UpltlVQq43oN0apFY14cci7du7TlghufYMgT47KWu/n+kRx9/j288eF0BvbZgTN/vQ/Nm+Zw0qVDeWl8Mr6/8O+C4rbt2pZeO3dj9rfzGTH+kyo5Fm2a8vLy+MMlFzHypREcMOhArr/hphIJXP4VvcWl9Aoq74rg2nqSuQBuv/Mf5HbpwnXXXsXcb7/dAEeRHjXhil95Cq5lFd8QYxwCDIG19/tJqykz5wKwVafsY/i6ZdZnG4dXXF7eGm57aDS3PTS6yPqGDerRY5v2LF22kk+nfbP2tWfMZbcdOrN159a8P3lWkX3q1NmM3PY/Y9WqvIKB4btsm0yocd+1J3HftSWn+23fpgXL3r8DgLa/uKjcZFU1X25ucpPUmTNmZN3+1cxkprjOuV2qpJ4tttiCSy67nEsuu7zI+rfefIMYIzv8fMeir9OlC1OnTKFJk6YlXqNJ02TdikzXUEkbnHF9I2jbsikv3PM7uue24bzrHy816cv3/NiPeH7sRyXW58/a/e4npc+QePqRfQAndVFRq1ev5rKLL2DkSyM4aPDB/PkvN1KnTp0S5XJycmjdpg3fzZ3L999/V2KcX0HsL3RbprLUq1+fPffsxdQpU5j04QcMaDtovY8lLWpC4pd/5q9ZKdubFitXK7369lQA9u+1LSGEIt0qG+c0oNfOXVm6bCVvTZqxzq9x3OA9aNSwPg899warV6/t0jH27SkcO3gPBvTenn+PKHqvvr133YrNGzVg3LtTWblqNQBvTprO5jnZp9g99fDeLFm2oqCeFZl9tGnruceeALw+cTxr1qwpMiPnkiWL+eD992jYsCE79sh+w98NXU++p4Y/AcBBgw8psj4/IHwxdQr77Nu3yLYvvkj+1tq1b1+h15BUgnG9mrVv3ZwXh5xLt44t+d11j6/zPfW2yW1D7527MX32D7wxKfvkXA3q1+XYwXuQl7eGB55xUhclVq1cyUUX/J4xo1/hkEMP45rr/lLm/XH32HMvnn/uWSaMH8dhhx9ZZNv4ca8VlKmo775LLpjUqVsTUp2aoyZ09fw8syxtztWtM8vSxgrUCtNn/8CoiZPJbd+SM3+9T5FtV5w1mMY5DXjkv2+xdPlKILkh+za5bejSoWWJuvK7Zha22/aduPbcQ1m0ZDnXD3mxyLanX/6A7+cv4uiBuxYZ+N2gfl2uOvtgAP75xNo+/cNHvsdvr3k06wNgwcKlBc+Xr1i1ju+IapKOnTrRq/fefD1nDv96rOitO+6643aWLVvKwYf+kpycZHKAVatWMX3al8wqdo+dytYDsGbNGpYuWUJxTw1/ghdfeJ7u227HQQcXTfyO+tWvqVu3Lg8/+ECRbiArVqzgjttuBWDQgYORtE6M69WoY9sWjLz3PLp2aMmZVz9aoaQv2++CVi0aM+z6U6hTZzMuv+3ZEreSynfEgF3YotnmjBj/iZO6CEgmcjn/vHMYM/oVDj/yqHKTPoCjf3UMAPfeczcLf1p7TmjOnNk8/tij1K9fv8h4vQUL5jN1yucl6gF4dewYRr/yMjk5Oey+e8+sZWqrUNof8kZrQHKT1y9Ipn3uVngGsBBCE+AbkgS1VYyx5K+7tWVjw53PruLWVq8uHVoyZtj/0uZnTfnPmA/5bPpcev68M3336M6UGXPpd8otBWP0Om25BZ+/cA0zv57HtoOvLFLPaw9eyLIVq/j0i69ZtHQF23XbkkF9tmfFqtUcc8G9vPz65BKvfUjfHjx602ksX7maJ156l/k/LWHwvjvSvUtbnhr1HsdffH+FjmHZ+3cwZ+58thpUO6bYXf7B2pnMl61Kd/eXWV99xUknHMOP8+bRb7/+dOnajY8mfcjbb71J59xcHnzkXzRv3gJIvsgPOqA/7dq158VRo9e5HoClS5bQb98+9OrVm46dkimf33v3HT7+aBIdO3binvuG0r59hxLtfXDYUP560w00a9acfv3706hRDhMnjGPmjBns2GMn7h36IA0blvwxlBaN6hVMyuSd6rVBbci4DpC22H5I3x4c0q8HkNxD74A+2zNt1vdMeP9LILm9wmW3Pl1Q/sJTBxTcVqlH9w7s1L0Dr3/wJV9kbgI/8YMvGfb02lmIJz9/FbntW/Lup18VzORd3EPPvcFX3/xY8Pwv5x/OgN7b8eak6fwwfzHt2zRn8L470rxJDlff9Tw3/HNEqcfz8n2/p8+uW3HkeXfzQimvlya1Ka4XNvqVlxnzyssA/PDD90ycMJ4OHTuy6667A9C8RQsuuOgSAK7442U898xTtGjRgl8dc1zWSVl277lHQS+ffDffeAMPPTCUNm3bMmDAQFatWsVLI15gwYIFXPqHKzj2+BMKyn42eTK/Puowttt+B7pttRWtW7dh0aKFfP7ZZ0z68APq1q3HdTfcyKADD6qqt6TGqUhcr/brnzHGL0MII0lm+DobuL3Q5quBzYF7ygoOtcX02T+w9/E3csVZBzOg93YM3HsHvv1hIXc+Oobr7nmR+QuXVqiep19+n6MG7sYxg3vSqEE9vvn+J4Y+8zo33z+ySCAo7D9jJ3HA6bdx8ekDOaz/zjSsX5cvZ/3AxTc/yZ2Pjd2AR6lNVcdOnXjs8Se5846/M3H8OMa99hqtWrXiuBNO5MyzzqFZ8xLzOGyQeurVr8+gAw/i/ffe5fXXk25GHTt25Kyzf8dJJ59KzubZbxV20imnktulCw8Ou5+XR77EypUr6dChI78951xOPvW0VCd9UlUyrpetR/cOnHho0S5rXTu2omvHVgDM/HpekcRvQO/t2Wf3rYuU77VzN3rt3K3geeHELzdzT97dtu/EbsVuz5DvtXemFon3r749hZ237cDBfXvQvEkj5i9cyqtvTeH2R8YUJKTZdO/Shj67buWkLrXA559N5rlnny6ybvasWQX3y23Xrn1B4vf1nOS+uvPnz+eefxS/lWfizN+eUyLxu/DiS9lmm+7869GHGT7832wWAtttvwMnn3oa+/btV6Rsu3btOP2MM3n3nbd5Y+JEFixYQN16ddlyyy056le/5vgTTqZrt26oqGq/4gcFZwcnAq2BZ4HJwJ5AP5KuIL1jjPPKqSP1V/y06amtZwZV83nFT1VpQ8V1SN8VP23ajOuqqSoS12vCGD9ijF8CuwPDSALDBUA34O9Ar/KCgyRJqjmM65JU81R7V898McZZwKnV3Q5JkrT+jOuSVLPUiCt+kiRJkqSqY+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSln4idJkiRJKWfiJ0mSJEkpZ+InSZIkSSkXYozV3YYNIoSQjgORpI0oxhiquw1SNsZ1Saq8suK6V/wkSZIkKeVSc8VPG1YI4YwY45DqbodUnJ9NSao8vztVU/nZ3Hi84qfSnFHdDZBK4WdTkirP707VVH42NxITP0mSJElKORM/SZIkSUo5Ez+Vxr7Wqqn8bEpS5fndqZrKz+ZG4uQukiRJkpRyXvGTJEmSpJQz8ZMkSZKklDPxU4EQQocQwv0hhK9DCCtCCDNCCH8LIbSo7rap9gohHBVCuD2EMC6EsDCEEEMID1d3uySppjOuqyYyrlefutXdANUMIYRuwESgNfAs8BmwB3AeMCiE0CfGOK8am6ja63JgJ2AxMBvYtnqbI0k1n3FdNZhxvZp4xU/57iIJDufGGA+LMV4aY9wPuBXoDlxXra1TbXY+sA3QFDirmtsiSZsK47pqKuN6NXFWTxFC6Ap8CcwAusUY1xTa1gT4BghA6xjjkmpppASEEPoCY4BHYownVHNzJKlGMq5rU2Fc37i84ieA/TLLkYWDA0CMcREwAcgB9trYDZMkSZVmXJdUgomfIOnyATCllO1TM8ttNkJbJEnS+jGuSyrBxE8AzTLLn0rZnr+++UZoiyRJWj/GdUklmPipIkJm6YBQSZI2fcZ1qRYy8ROsPfPXrJTtTYuVkyRJNZdxXVIJJn4C+DyzLK2v/9aZZWljBSRJUs1hXJdUgomfIJlGF+CAEEKRz0Rm2uc+wDLgjY3dMEmSVGnGdUklmPiJGOOXwEggFzi72Oargc2BB73XjyRJNZ9xXVI23sBdAIQQugETgdbAs8BkYE+gH0lXkN4xxnnV10LVViGEw4DDMk/bAgOBacC4zLofYowXVkfbJKmmMq6rpjKuVx8TPxUIIXQErgEGAT8DvgGeAa6OMf5YnW1T7RVCuAq4sowiM2OMuRunNZK06TCuqyYyrlcfEz9JkiRJSjnH+EmSJElSypn4SZIkSVLKmfhJkiRJUsqZ+EmSJElSypn4SZIkSVLKmfhJkiRJUsqZ+EmSJElSypn4SZIkSVLKmfjVYiGEWOyRF0L4IYQwOoRwfAXL/xhCGBtCOCWEELLsk5tlv2yP3EL7XFVs25oQwsIQwswQwgshhEtCCO1LOab815tRxnHvEUK4L4TweQhhUQhhRabu4SGEX4UQ6lSi3YUffTP1j61A2avKeY+WhRC+CyG8EUK4I4Twi0r81xY/3s1CCEeFEJ4MIcwKISwPISwJIUwOIQwJIfQpVv6UTBuGrcNrjcrsOyuEUKecsj1DCI9k3vsVmf/jL0MI/wkhXBxC2DzLPkeHEEZk3ptVIYR5IYRPQwgPhxBOrmx7JSlNjOvGdeO6ylK3uhugGuHqzLIe0B04DOgXQtgtxvi/5ZTfCjgc2BfYHTinlNf4CfhbGW1YkGXdq8DYzL83B7YE+gAHAleHEK6KMd5QRp1FhBDqAX8HzgTyMvX/F1gBdAD2A44EngROZ+1xFnZlZplt24xizx/Isi7f2CzrCr9HdYEtgJ2As4CzQwgjgZNijHNLqbOEEEJbYDjJ+7YIGAV8CQRga+BY4DchhHNjjLdXtN5SXqsr0B+IJO/ngcDzpZQ9geT9CcBo4GmS/5MuJJ+jg4GngC8K7TME+A2wjOT/bTrJ56IrcAjQN1OnJNV2xnXjunFdJcUYfdTSB8kfcsyyvj+wJvPIrUD5PiR/3GuALsW25Wb2m1GJdl2V2eeqLNsCyZf4vEyZSyv6esCQzLZJQPcs2+sAJwBPVPY9K1ZmbKZc3woeb5nvEckX4JhMmfeBhhWsNwf4ILPfY0CLLGWaAtcAfyy07pTMPsMq+Xn6S2a//OVzZbTrJ2A10L+UMr2B5sU+YxGYBXTIUr4eMGBD/W348OHDx6b4MK6X2G5cj8Z1H2sfdvVUCTHGV4DPSL6Me1ag/IRC5Xer4rbFGOOTwFGZVVeGELYsb78QQm+Ss0o/AgNjjJ9nqTsvxvgwSZCoMWKM04DBJO/xziRnNivifJIzixOA42OM87PUvTDG+Cfg5vVpYwihLklgWUgScN4DDiql687PSQLTx5nPWgkxxokxxsJni/O7rTwZY5ydpfyqGOOo9TgESUot47pxvbKM6+lk4qfS5Pfrj5Usv6oK2lJCjHEMMB5oCBxRgV3+X2Y5JMb4TTl1r1jP5m1wMcalrP0SLzFOoxRnZJbXxhjXlFP/+h7zoUBb4PEY4zJgGMmZ1v/JUnZeZtkuW3//UuTvs836NFKSajHjeg1iXDeuVwfH+KmEEML+JGMCIvB2Bcrvkym/EnirlGLNCw98LubbGOPd69DUscDewB7AneWU3TuzzHomqoqckj8wPIu7Y4zfVrK+sZnlLiGEujHG1aUVDCF0BDqRdLt4tZKvsy7yg9HQzPJRkoB2WgjhumIBahrJ56onMCGE8E9gIvBJjHFlKfWPIOlGcmAI4TngX5k6vogxVvRHjCTVSsb1Dca4blzfpJn4iUJf3IUHgQfg1hjjzHLK5w8CD8CFZZx1a8baAdTFfQisS4CYk1m2qkDZ/G4jJboTVKGyZqN6BqhsgMg/3jokA8S/K6Ns/vHOizEur+TrVEoIoTMwAPg8xvg6QIxxXgjheZKztgeQfMGT2RZDCEeRDNjuC9yR2bQqhPA+yeDvf8QYFxbaZ04I4XDgnyQDvg/JbFoUQpgIPAw8FmPMq7ojlaRNg3G9yhjXjeubNBM/wdov7kgyC9c44L5Mv/iyyueLwGkxxqHZCmfMjDHmrlcrS6pst5XKll1f/WKMYzdgfYWn1S7vONblvVlXp5N0Gx9WbP0wkgBxBoUCBECM8SuSGea2Iwkuu5Oc4c1//DaE0DfGOL3QPmNCCNuQjAvYF9gl8++BmcfJIYSDa2KXHknayIzrVcO4blzfpJn4iRhjifv0VKR8ph93L+A+4O4QwswY4+gqaGJp2mWW31eg7Dcks2h1AEoMAN9E5B9vHlBiQHcxX2eWLUMIDavq7GDmnj6nksz89lCxzS+SnP08JITQNlsXmBjjZGByofq2Be4n+VzdSnKWunD5NSQ/YMZlygeSAPMAsD/JFNllTS8uSalnXN9kGNeN6xuVk7toncUYl8QYXya5PF8HeCCEkLMRm9Avs3yzAmXHZ5b9q6gtG0P+8b5b1jgAgBjjLOArkpM7+1Rhmw4G2pN8l8wOhW5WSzIhQNtMG7INBi8hxvgZcGLm6X4VKB9jjCOByyu6jyQpO+P6RmdcL1neuF6FTPy03mKMk0j6aHcgmWq4yoUQ9iPpDrCM5Cah5RmSWZ4RQmhTTt0N1rN5G1wm8F6QefpIBXfLP+bLQwhl/q2vxzH/JrN8nuQMcfHHsMz20zNn8SpiUX6zKtGOddlHkpSFcb3qGderZB+Vw8RPG8qfgeXAhSGEFlX1IiFxBPBEZtWVFZlFK3NPon8CPwNGhBC2zlL3ZiGEYynZtaFahRC6AP8FtiW50es9Fdz1VpIB9r8AHgwhNM9Sd+MQwp+AC9ehXR2AQSTdU46OMZ6e5XEqyVnZLiRdNgghdAkhnBtCaJalzgD8MfP0tULrB4UQjggh1Mt2DMDvi+8jSVovxvUqYlw3rlcXx/hpg8jMznQPcB5wMXBZsSJlTfsMMCzGOKPYur6F9mlE0he+D8mXzQrgkhjjTZVo5tkk/ejPBCaHEMaSfIGuIOnWsB/J2c3hlaizLGVN+/xBjPGZYusKv0d1gRYkN2rtRXKSZgRwckUHOccYl4YQBpEcz/EkffJHAV9k6tuKpItMU+CcLFXsHUIYVkr175HMQFYHeLicsQb3kky7fQYwimQmuNuAm0IIE4CPSc7stSb5P+hKMrPZBYXq2JYk4M0PIYwDppJMad2B5Ca4zUm6Bt2BJGm9GdezMq4njOubqOCtMmqvTH/tCg8CL698pqvFtMzTrjHGuSGEXGB6tvLFFMyUlfmSLDzDWASWAD8Cn5Dcv+bhGOOcYnVQ6PVKnW0shLAnyZfVL0iCTj2SL6R3gMeA4bGUG6NW5D3LBJ59S9ue8UCM8ZRibS5sBbCQtffGeTzGOJ51kOkOciRwLMnMWi1JBm1/RXLW7v4Y48RC5U9h7X17SvMfYGegI7BTpltQaa+fQzIoPYfkC/0n4ECS6aD3IgnOWwBLSYLXCOBvMcbvC9XRkuRmsgNIguaWQGOS2eo+JjlTfG8Z9wuSpNQzrhvXMa6rDCZ+kiRJkpRyjvGTJEmSpJQz8ZMkSZKklDPxkyRJkqSUM/GTJEmSpJQz8ZMkSZKklDPxkyRJkqSUM/GTJEmSpJQz8ZMkSZKklDPxkyRJkqSUM/GTJEmSpJT7Pxqmv2UEDL36AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Compute confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "class_labels = [0,1]\n",
    "cm=confusion_matrix(test_df['sentim'].values, test_pred_ints, labels=class_labels)\n",
    "plot_confusion_matrix(confusion_matrix=cm, class_names=class_labels, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentim_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this movie was awesome</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this movie was the worst movie ive ever seen</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i hated everything about this movie.  it was a waste.</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is my favorite movie of the year</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews sentim_pred\n",
       "0                                 this movie was awesome         pos\n",
       "1           this movie was the worst movie ive ever seen         neg\n",
       "2  i hated everything about this movie.  it was a waste.         neg\n",
       "3                  this is my favorite movie of the year         pos"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict sentiment of four new reviews.  \n",
    "#Sentiment: 1 - Positive or 0 - Negative.\n",
    "\n",
    "def prepare_predict_data(reviews):\n",
    "    '''\n",
    "    Convert review texts to integer sequences.  Adjust each sequence\n",
    "    to maxlen by padding or truncating.\n",
    "    '''\n",
    "      \n",
    "    #create tokenizer for our data\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=8000, oov_token='<UNK>')\n",
    "    tokenizer.fit_on_texts(train_df['review'])\n",
    "    \n",
    "    seqs = tokenizer.texts_to_sequences(reviews)\n",
    "    seqs = tf.keras.preprocessing.sequence.pad_sequences(seqs, maxlen=256, padding=\"post\")\n",
    "    return seqs\n",
    "\n",
    "my_reviews=['this movie was awesome',\n",
    "           'this movie was the worst movie ive ever seen',\n",
    "           'i hated everything about this movie.  it was a waste.',\n",
    "           'this is my favorite movie of the year']\n",
    "my_seqs = prepare_predict_data(my_reviews)\n",
    "\n",
    "new_preds= hyp_model.predict(my_seqs)\n",
    "new_preds_int = [int(i>0.5) for i in new_preds]\n",
    "\n",
    "#Summarize new reviews and predictions in dataframe.\n",
    "wild_df = pd.DataFrame(columns=['reviews','sentim_pred'])\n",
    "wild_df['reviews'] = my_reviews\n",
    "wild_df['sentim_pred'] = new_preds_int\n",
    "wild_df['sentim_pred'].replace({1: 'pos', 0: 'neg'}, inplace=True)\n",
    "wild_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model runtime: 23.653537011146547\n"
     ]
    }
   ],
   "source": [
    "mend=time.time()\n",
    "print('model runtime:', (mend-mstart)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/mpeg;base64,SUQzAwAAAAAAJlRQRTEAAAAcAAAAU291bmRKYXkuY29tIFNvdW5kIEVmZmVjdHMA//uSwAAAAAABLBQAAAL6QWkrN1ADDCBAACAQBAQECQD//2c7OmpoX/btmzIxt4R/7tmdKRqBVldEDICeA2szOT5E0ANLDoERvAwYDvXUwGPgUBhQVAiIAGFQb9toDBQAwSGwMLgECIPAUE/7v4YoAwyHQMSh8BgNl0r//5ofWmt///4swTaBg0CgSAgNoClQMSAwCgBAwiA//t9/GRFBlcXORYXAN8ZQggBgCACBH////4WYFjpmaRcLZcYggswUoBgEEgYPBf////////+VwfOBAwA7llUiIABQAAAgAAAEBgUARBzKEVmNPo26GUFGinz0RnZcAARtaVqlvTwGDx8BvHbgkEQMtcYIQgBjzkgaETYGFhuAEeRQ5m4ZcMEAsmKArYXE7qZFkXGOGkI5L4yqTIqRZNK45ociBkoKE6brSDUgMNi8mkJqHfAwaMBz11/t23+yEgox4FicKWLheWtJMWkAYIGpvvKwpgAQBJxVki+QFZOmhfJkQWCICACENuqdNB1Ba39WSI1wxkIsPSalHkFsZloPyHLBoEwssSa3Xf/7ksBnABz9nUn5qoACZTMov7FQAGsyLZRDwG7X+vJcfAjUzWVJMUz/DadX/DPVVPTwxgAAYggAShABbnnd5DQOPbj70zVpiaxayfheoOiDfgbrAYWXYHf90BlMZAYvDQUAYhKOIfxmTyebVJ71qsPaSBSPnR4NTPoOShOniyMyQEMSAScgXMjmnkkTJ71ob1q2rei1TUOy0Ss5w4QYIA0HbOG3Pf//3+j8i6LMiQ0CAFFXbU9Xf//+/mJHJOsyLwYXJ1mr16/1AJZ4ZlMAACAAADEFHpoLU2ytFsJ1sql3c1hG7r4LivRJ06AgAMwNgSDQUFJMGgAAOAXR8a+/8op8Ln/Z5+X/z+4/yc+vLe5V+QXz/52DO8uxhuYWBWA9SESgTZOJpmtaG2rbR2u29NqluNQrUjU4EoAfZG1SNfVX/928+3ccDzJEmgCCQc41Szj/V9S/r+o29Qn1qrhQY9Wg/rb/9fzku8RCoAABQAABKjQCK1VNcqoJHKmjjRanrzeKUiQHJyu63xb0wtDo+TRcFFkPAS68UpPuY2f+v/4/+///+5LAbIATtdU/7HqNwlm0aD2O0bDv9q3qS1nq12Z9yUSRRMBjQF4wHfMidi6aVlt2PVI7a6n11d7ashxpscCbQWBa2qP1tnq22q7VatDVj01aygAkcI0TXnHr1tX2/W+qrqmQ03rwUBNXnK7dvTeRh2VkYwAAKAAANmkNuUCQrNCopStlXHuCRUS6Xmb1FJdyyQKCxhEZZ3xiBiIE5ZJ45VZj9nK/39d7n/5////b0Sx1MW7zwd/89STW8J+EAoCwJcYM2OAvmjE5VzayGr+nvpash5arY4EJIBQOJrNaZL1tUtS9v9uqd08Zl2RSIaASHQ402MXko1etvr+632qPbKLI3F1YDQRecybarX+3qq+o+upVkRCAAAgAAAZGbDPFHmW35hRX4JfLKULFfuWuey1yVKB0FwsZRmlgZgIFCHdUjlw/BVq9h3Cxnzv4Y5659JYr7ortvLj4fn/eR6xq5K3oC4vgc9EKDIAQdSBMspPTXT3+m/tOp1oR0qQtBCwCiw3RPTpb+qvtV6mbzJqGMtZSBTAMIhsaBxUyNXV0GV0l//uSwJkAFGnXPex2rcKXuuf9jtG4L9f0z2nQFK1JqQAUDM681f7/Zf1e82WAioiGUwAAMAAAKBrafL7Ku+qidGFD4nVyacggTALkCEoYIANAGBgXCWBiVFyBp/PgBhGCEAMFAMVk+dH2TBoYrm9BHTe8nCjIANs3I8ixWIx9JAjDVNA6IXAeEUDDEBoBQCAuBTqPtesy39Nt61bVKrZRgnRMDwIQGA4EBFC0aIHUG/9/1P/pUBjTdzhgOgBwDBF1qQrb1Nv/v+tfWok07GBcC4En3VljsdIclUMYgIgAAAAAAAAAAAASAeJK1eXElURk3DcGCI9jsylQ8LhANGAxQ48DSKDgORA0gBiAYAwXjYCQG0TUCwHBzEUHUy2WsrkHMi4kpqDJuxmVE5bNC+GOAYPAailFSeFzgYZQCCf1rIiJtAwuASGAkyNqtKt9Zmmo0NE1npbEqCAAZga6aaQ5YDQMiJm+VzQqiugHAgLRxk7b6x6FDBZX75ZUM+BYBydBk7okIKFC+iTM9m1zp8pB4zfVX1uU2H2I2agtPQdZuiWhqv/7ksC6gBV1o0P1iwADaDro+x9gAEEdFvX///mZ/eT/6Dx8wAyYoAUAAAADAEAFAAAAAAPVTzyO6U2P8w8nM8P6bv+PBRjw07pfb/AciANoiwLBCM1LAysBAFCABgMGhMABswkysR0CIHAMAAMBiAo5JOE9XhikQ4LmBQgtKRMlgyJ74xQblBiMCQEEeCOyis1IcTRb/IEKMJ0FbiyRtCUCGmKBskYnP43B0i4xpidRkB2DlmSRsUTE8ZGTl3/juHAOeOaSQzA/ENHPGXE+oqeicUbFExb/5UKhAzhEiIEXIqViCEoQ0i46x2GSTooqeipSRii3//YliLmBPE4RcmSsQQjP//mQ0nLjQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/+5LAvgAcldNN2bqASAAAJYOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA//uSwP+AAAABLAAAAAAAACWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/7ksD/gAAAASwAAAAAAAAlgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/+5LA/4AAAAEsAAAAAAAAJYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA//uSwP+AAAABLAAAAAAAACWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/7ksD/gAAAASwAAAAAAAAlgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/+5LA/4AAAAEsAAAAAAAAJYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA//uSwP+AAAABLAAAAAAAACWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/7ksD/gAAAASwAAAAAAAAlgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAD/+5LA/4AAAAEsAAAAAAAAJYAAAAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAgACAAIAAA\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Beep when code is done.\n",
    "from IPython.display import Audio\n",
    "sound_file = 'https://www.soundjay.com/button/sounds/beep-07.mp3'\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.tensorflow.org/tutorials/text/word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Reset current tensorflow session, learning phase, and graph.\n",
    "# keras.backend.clear_session()\n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "\n",
    "# #Use model like a Scikit-Learn object\n",
    "# model = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "\n",
    "# #Callbacks - early stop and save best model\n",
    "# early_stop_cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max')\n",
    "# checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model.h5\", save_best_only=True)\n",
    "\n",
    "# #Fit TensorFlow 2 model.\n",
    "# history = model.fit(train_seqs, train_df['sentim'].values, batch_size=BATCH_SIZE,\n",
    "#                     epochs=EPOCHS, validation_split=0.2, callbacks=[early_stop_cb, checkpoint_cb])\n",
    "\n",
    "# print(history.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyp_grid = {\n",
    "#     \"vocabSize\": [8000], #can this be reduced?\n",
    "#     \"embeddedDim\": [4,8],\n",
    "#     \"batch_size\": [16, 32],\n",
    "#     \"epochs\": [20],    \n",
    "# }\n",
    "\n",
    "# #Callbacks - early stop and save best model\n",
    "# early_stop_cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max')\n",
    "# checkpoint_cb_hpsearch = keras.callbacks.ModelCheckpoint(\"hyp_model.h5\", save_best_only=True)\n",
    "\n",
    "# #Use model like a Scikit-Learn object\n",
    "# class_model = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "\n",
    "# hyp_model = RandomizedSearchCV(class_model, hyp_grid, n_iter=2, cv=3, verbose=2)\n",
    "\n",
    "# hyp_model.fit(train_seqs, train_df['sentim'].values, validation_split=0.2, \n",
    "#               callbacks=[early_stop_cb, checkpoint_cb_hpsearch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hyp_model best parameters and score\n",
    "# print('best params:', hyp_model.best_params_, '\\n')\n",
    "# best_score_std = hyp_model.cv_results_['std_test_score'][hyp_model.best_index_]\n",
    "# print(f'best score: {hyp_model.best_score_:.4f} +/- {best_score_std:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
